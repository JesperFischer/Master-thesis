---
title: "Legrand analysis"
output: html_document
date: "2024-03-27"
---


```{r}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(cmdstanr, tidyverse,posterior, bayesplot, tidybayes, furrr,LRO.utilities)
```

# single fit model
```{r}

source(here::here("Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("Legrand reanalysis","single_fit_nolapse","singlefit_nolapse.stan"))

i = 1
ss = 1

dfbig = data.frame()
for(i in 1:length(unique(hrd$s))){
  for(ss in 1:2){
    df = hrd %>% filter(s == unique(hrd$s)[i] & session == ss)
    
    
    
    datastan = list(n = df %>% .$n,
                    y = df %>% .$y,
                    x = df %>% .$x,
                    N = nrow(df))
    
    fit <- mod$sample(
      data = datastan, 
      iter_sampling = 1000,
      iter_warmup = 1000,
      chains = 4,
      parallel_chains = 4,
      refresh = 100,
      adapt_delta = 0.90,
      max_treedepth = 12,
    )
    
    dd = data.frame(fit$summary(c("alpha","beta"))) %>% mutate(id = unique(hrd$s)[i],
                                                               div = mean(fit$diagnostic_summary("divergences")$num_divergent),
                                                               session = ss)
    
    dfbig = rbind(dfbig,dd)
    
  }
}


#write.csv(dfbig, here::here("realshit","Legrand reanalysis","single_fit_nolapse","single_fit_nolapse.csv"))
```
# Nolapse RTS

```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","single_fit_nolapse","singlefit_nolapse_rt.stan"))

i = 1
ss = 1

dfbig_rt = data.frame()
for(i in 1:length(unique(hrd$s))){
  for(ss in 1:2){
    df = hrd %>% filter(s == unique(hrd$s)[i] & session == ss)
    
    print(i)
    datastan = list(n = df %>% .$n,
                    y = df %>% .$y,
                    x = df %>% .$x,
                    RT = df %>% .$RT,
                    minRT = min(df %>% .$RT),
                    N = nrow(df))
    
    fit <- mod$sample(
      data = datastan, 
      iter_sampling = 1000,
      iter_warmup = 1000,
      chains = 4,
      refresh = 0 ,
      parallel_chains = 4,
      adapt_delta = 0.90,
      max_treedepth = 12,
    )
    
    dd = data.frame(fit$summary(c("alpha","beta","intercept","betart","sigma","ndt"))) %>% mutate(id = unique(hrd$s)[i],
                                                               div = mean(fit$diagnostic_summary("divergences")$num_divergent),
                                                               session = ss)
    
    dfbig_rt = rbind(dfbig_rt,dd)
    
  }
}

#write.csv(dfbig_rt, here::here("realshit","Legrand reanalysis","single_fit_nolapse","single_fit_nolapse_rt.csv"))

dfbig_rt = read.csv(here::here("realshit","Legrand reanalysis","single_fit_nolapse","single_fit_nolapse_rt.csv"))

correlations_rt = get_things(dfbig_rt, n_div = 3)  

correlations_rt
```

# Nolapse full

```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","single_fit_nolapse","singlefit_nolapse_full.stan"))

i = 1
ss = 1

dfbig_full = data.frame()
for(i in 1:length(unique(hrd$s))){
  for(ss in 1:2){
    df = hrd %>% filter(s == unique(hrd$s)[i] & session == ss)
    
    
    df = df %>% mutate(Confidence = ifelse(Confidence == 0, 0.01, ifelse(Confidence == 100, 0.99, Confidence/100))) %>% drop_na()
    
    datastan = list(n = df %>% .$n,
                    y = df %>% .$y,
                    x = df %>% .$x,
                    RT = df %>% .$RT,
                    minRT = min(df %>% .$RT),
                    conf = df %>% .$Confidence,
                    N = nrow(df))
    
    fit <- mod$sample(
      data = datastan, 
      iter_sampling = 1000,
      iter_warmup = 1000,
      chains = 4,
      parallel_chains = 4,
      refresh = 0,
      adapt_delta = 0.90,
      max_treedepth = 12,
    )
    
    dd = data.frame(fit$summary(c("alpha","beta","intercept","betart","sigma","ndt",
                                  "intercept_conf","beta_conf","sigma_conf"))) %>% mutate(id = unique(hrd$s)[i],
                                                               div = mean(fit$diagnostic_summary("divergences")$num_divergent),
                                                               session = ss)
    
    dfbig_full = rbind(dfbig_full,dd)
    
  }
}

#write.csv(dfbig_full, here::here("realshit","Legrand reanalysis","single_fit_nolapse","single_fit_nolapse_full.csv"))

dfbig_full  = read.csv(here::here("realshit","Legrand reanalysis","single_fit_nolapse","single_fit_nolapse_full.csv"))


correlations_full = get_things(dfbig_full, n_div = 3)  

correlations_full
```

# With lapse

```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","single_fit_lapse","singlefit_lapse.stan"))

i = 1
ss = 1
dfbig_lapse = data.frame()


for(i in 1:length(unique(hrd$s))){
  for(ss in 1:2){
    df = hrd %>% filter(s == unique(hrd$s)[i] & session == ss)
  
    
    
    datastan = list(n = df %>% .$n,
                    y = df %>% .$y,
                    x = df %>% .$x,
                    N = nrow(df))
    
    fit <- mod$sample(
      data = datastan, 
      iter_sampling = 1000,
      iter_warmup = 1000,
      chains = 4,
      parallel_chains = 4,
      refresh = 0,
      adapt_delta = 0.90,
      max_treedepth = 12,
    )
    
    dd = data.frame(fit$summary(c("alpha","beta","lambda"))) %>% mutate(id = unique(hrd$s)[i],
                                                               div = mean(fit$diagnostic_summary("divergences")$num_divergent),
                                                               session = ss)
    
    dfbig_lapse = rbind(dfbig_lapse,dd)
    
  }
}


#write.csv(dfbig_lapse, here::here("realshit","Legrand reanalysis","single_fit_lapse","single_fit_lapse.csv"))

dfbig_lapse = read.csv(here::here("realshit","Legrand reanalysis","single_fit_lapse","single_fit_lapse.csv"))


correlations_lapse = get_things(dfbig_lapse, n_div = 3)  

correlations_lapse
```


# With lapse and rt

```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","single_fit_lapse","singlefit_lapse_rt.stan"))

i = 1
ss = 1
dfbig_lapse_rt = data.frame()


for(i in 1:length(unique(hrd$s))){
  for(ss in 1:2){
    df = hrd %>% filter(s == unique(hrd$s)[i] & session == ss)
  
    
    
    datastan = list(n = df %>% .$n,
                    y = df %>% .$y,
                    x = df %>% .$x,
                    RT = df %>% .$RT,
                    minRT = min(df %>% .$RT),
                    N = nrow(df))
    
    fit <- mod$sample(
      data = datastan, 
      iter_sampling = 1000,
      iter_warmup = 1000,
      chains = 4,
      parallel_chains = 4,
      refresh = 0,
      adapt_delta = 0.95,
      max_treedepth = 12,
    )
    
    dd = data.frame(fit$summary(c("alpha","beta","lambda","intercept","betart","sigma","ndt"))) %>% mutate(id = unique(hrd$s)[i],
                                                               div = mean(fit$diagnostic_summary("divergences")$num_divergent),
                                                               session = ss)
    
    dfbig_lapse_rt = rbind(dfbig_lapse_rt,dd)
    
  }
}

#write.csv(dfbig_lapse_rt, here::here("realshit","Legrand reanalysis","single_fit_lapse","single_fit_lapse_rt.csv"))
```
# with lapse rt and conf:

```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","single_fit_lapse","singlefit_lapse_full.stan"))

i = 1
ss = 1
dfbig_lapse_full = data.frame()


for(i in 1:length(unique(hrd$s))){
  for(ss in 1:2){
    df = hrd %>% filter(s == unique(hrd$s)[i] & session == ss)
  
    df = df %>% mutate(Confidence = ifelse(Confidence == 0, 0.01, ifelse(Confidence == 100, 0.99, Confidence/100))) %>% drop_na()
    
    datastan = list(n = df %>% .$n,
                    y = df %>% .$y,
                    x = df %>% .$x,
                    RT = df %>% .$RT,
                    minRT = min(df %>% .$RT),
                    conf = df %>% .$Confidence,
                    N = nrow(df))
    
    fit <- mod$sample(
      data = datastan, 
      iter_sampling = 1000,
      iter_warmup = 1000,
      chains = 4,
      parallel_chains = 4,
      refresh = 0,
      adapt_delta = 0.95,
      max_treedepth = 12,
    )
    
    dd = data.frame(fit$summary(c("alpha","beta","lambda","intercept","betart","sigma","ndt",
                                  "intercept_conf","beta_conf","sigma_conf"))) %>% mutate(id = unique(hrd$s)[i],
                                                               div = mean(fit$diagnostic_summary("divergences")$num_divergent),
                                                               session = ss)
    
    dfbig_lapse_full = rbind(dfbig_lapse_full,dd)
    
  }
}

write.csv(dfbig_lapse_full, here::here("realshit","Legrand reanalysis","single_fit_lapse","single_fit_lapse_full.csv"))
```

#  combining no lapse results:
```{r}
#without lapse
bootstrap_correlation_unc <- function(mx,my,sdx,sdy, truncated) {
  
  df1 = data.frame(mx = mx, my = my, sdx = sdx, sdy = sdy)
  
  ind <- sample(nrow(df1), nrow(df1), replace=TRUE)
  
  if(truncated){
    df1 = df1 %>% rowwise() %>% mutate(x = truncnorm::rtruncnorm(1,0,Inf, mx, sdx),
                                       y = truncnorm::rtruncnorm(1,0,Inf, my, sdy)) %>% unnest(cols = c()) %>% as.data.frame(.)
  }else{
    df1 = df1 %>% rowwise() %>% mutate(x = rnorm(1, mx, sdx),
                                       y = rnorm(1, my, sdy)) %>% unnest(cols = c()) %>% as.data.frame(.)
  }

  return(cor.test(df1[ind, 1], df1[ind, 2], method = "pearson",exact = FALSE)$estimate[[1]])
}


get_things = function(df, n_div = 10){
  
  # times 2 because there are two sessions
  print(paste0("participants excluded (i.e. both their sessions) : "))
  (nrow(df) - nrow(df %>% select(mean,sd,variable, session, div,id) %>% group_by(id)%>% filter(any(div < n_div)))) / (length(unique(df$variable)) * 2)
  
  cor_nouncertainty = df %>% select(mean,sd,variable, session, div,id) %>% group_by(id)%>% filter(any(div < n_div)) %>% select(-div, id) %>%
    group_by(variable) %>%
    summarize(correlation_mean = cor.test(mean[session == 1], mean[session == 2])$estimate[[1]],
              correlation_q5 = cor.test(mean[session == 1], mean[session == 2])$conf.int[[1]],
              correlation_q95 = cor.test(mean[session == 1], mean[session == 2])$conf.int[[2]])

  
      cor_nouncertainty$text = paste0(sprintf("%.2f",(round(cor_nouncertainty$correlation_mean,2))), " [", sprintf("%.2f",(round(cor_nouncertainty$correlation_q5,2))), " ; ",sprintf("%.2f",(round(cor_nouncertainty$correlation_q95,2))), "]")
  
  cor_uncertainty = df %>% select(mean,sd,variable, session, div,id) %>% group_by(id)%>% filter(any(div < n_div)) %>% select(-div, id) %>% 
    group_by(variable) %>% mutate(id = list(1:1000)) %>% unnest() %>% group_by(variable,id) %>% 
    summarize(correlation = ifelse(variable == "alpha",
                                 bootstrap_correlation_unc(mean[session == 1], mean[session == 2],
                                                           sd[session == 1], sd[session == 2], F),
                                 bootstrap_correlation_unc(mean[session == 1], mean[session == 2],
                                                           sd[session == 1], sd[session == 2], T))) %>% 
    group_by(variable) %>% 
    summarize(mean = mean(correlation),
              q5 = HDInterval::hdi(correlation)[[1]],
              q95 = HDInterval::hdi(correlation)[[2]])
  
  
   cor_uncertainty$text = paste0(sprintf("%.2f",(round(cor_uncertainty$mean,2))), " [", sprintf("%.2f",(round(cor_uncertainty$q5,2))), " ; ",sprintf("%.2f",(round(cor_uncertainty$q95,2))), "]")
  
  
  
  return(list(cor_nouncertainty, cor_uncertainty))
}
  

make_table_noun = function(cor){
  paste0(round(cor$correlation_mean,2), " [", round(cor$correlation_q5,2), " ; ",round(cor$correlation_q95,2), "]")
  
}


dfbig = read.csv(here::here("realshit","Legrand reanalysis","single_fit_nolapse","single_fit_nolapse.csv"))

correlations = get_things(dfbig, n_div = 3)

d4 = rbind(
  correlations[[1]] %>% select(variable,text) %>% mutate(propergated_uncertainty = FALSE, lapse = F, model = "Binary", structure = "Single"),
  correlations[[2]] %>% select(variable,text) %>% mutate(propergated_uncertainty = TRUE, lapse = F, model = "Binary", structure = "Single")
)




dfbig_rt = read.csv(here::here("realshit","Legrand reanalysis","single_fit_nolapse","single_fit_nolapse_rt.csv"))

correlations_rt = get_things(dfbig_rt, n_div = 3)  

d5 = rbind(
  correlations_rt[[1]] %>% select(variable,text) %>% mutate(propergated_uncertainty = FALSE, lapse = F, model = "RT", structure = "Single"),
  correlations_rt[[2]] %>% select(variable,text) %>% mutate(propergated_uncertainty = TRUE, lapse = F, model = "RT", structure = "Single")
)



dfbig_full  = read.csv(here::here("realshit","Legrand reanalysis","single_fit_nolapse","single_fit_nolapse_full.csv"))


correlations_full = get_things(dfbig_full, n_div = 3)  

d6 = rbind(
  correlations_full[[1]] %>% select(variable,text) %>% mutate(propergated_uncertainty = FALSE, lapse = F, model = "RT+Conf", structure = "Single"),
  correlations_full[[2]] %>% select(variable,text) %>% mutate(propergated_uncertainty = TRUE, lapse = F, model = "RT+Conf", structure = "Single")
)



```

#  combining with lapse results:
```{r}
#with lapse

dfbig_lapse = read.csv(here::here("realshit","Legrand reanalysis","single_fit_lapse","single_fit_lapse.csv"))


correlations_lapse = get_things(dfbig_lapse, n_div = 3)  

correlations_lapse

d3 = rbind(
  correlations_lapse[[1]] %>% select(variable,text) %>% mutate(propergated_uncertainty = FALSE, lapse = T, model = "Binary", structure = "Single"),
  correlations_lapse[[2]] %>% select(variable,text) %>% mutate(propergated_uncertainty = TRUE, lapse = T, model = "Binary", structure = "Single")
)

dfbig_lapse_rt = read.csv(here::here("realshit","Legrand reanalysis","single_fit_lapse","single_fit_lapse_rt.csv"))

correlations_lapse_rt = get_things(dfbig_lapse_rt, n_div = 3)  

correlations_lapse_rt

d2 = rbind(
  correlations_lapse_rt[[1]]%>% select(variable,text) %>% mutate(propergated_uncertainty = FALSE, lapse = T, model = "RT", structure = "Single"),
  correlations_lapse_rt[[2]]%>% select(variable,text) %>% mutate(propergated_uncertainty = TRUE, lapse = T, model = "RT", structure = "Single")
)


dfbig_lapse_full = read.csv(here::here("realshit","Legrand reanalysis","single_fit_lapse","single_fit_lapse_full.csv"))

correlations_lapse_full = get_things(dfbig_lapse_full, n_div = 3)  

correlations_lapse_full

d1 = rbind(
  correlations_lapse_full[[1]]%>% select(variable,text) %>% mutate(propergated_uncertainty = FALSE, lapse = T, model = "RT+Conf", structure = "Single"),
  correlations_lapse_full[[2]]%>% select(variable,text) %>% mutate(propergated_uncertainty = TRUE, lapse = T, model = "RT+Conf", structure = "Single")
)



rbind(d1,d2,d3,d4,d5,d6) %>% filter(variable %in% c("alpha","beta"))
```




## Get data  (single hierarchical model)
```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","test retest nort.stan"))

df = hrd


datastan = list(Y = cbind(df %>% filter(session == 1) %>% .$y, df %>% filter(session == 2) %>% .$y),
                N = nrow(df),
                N_s1 = nrow(df %>% filter(session == 1)),
                N_s2 = nrow(df %>% filter(session == 2)),
                C = 2,
                npx = cbind(df %>% filter(session == 1) %>% .$n, df %>% filter(session == 2) %>% .$n),
                S = length(unique(df$s)),
                S_id = cbind(df %>% filter(session == 1) %>% .$s, df %>% filter(session == 2) %>% .$s),
                X =  cbind(df %>% filter(session == 1) %>% .$x, df %>% filter(session == 2) %>% .$x))

# fit <- mod$sample(
#   data = datastan, 
#   iter_sampling = 1000,
#   iter_warmup = 1000,
#   chains = 4,
#   parallel_chains = 4,
#   refresh = 100,
#   init= 0,
#   adapt_delta = 0.90,
#   max_treedepth = 12,
# )

#fit$save_object(here::here("realshit","Legrand reanalysis","workspace","correlation_nort.RDS"))


correlation_nort <- readRDS(here::here("realshit","Legrand reanalysis","workspace","correlation_nort.RDS"))



mean_cor = matrix(correlation_nort $summary("correlation_matrix") %>% .$mean, byrow = T, nrow = 6)
colnames(mean_cor) = c("alpha_ses1","beta_ses1","lambda_ses1","alpha_ses2","beta_ses2","lambda_ses2")
rownames(mean_cor) = c("alpha_ses1","beta_ses1","lambda_ses1","alpha_ses2","beta_ses2","lambda_ses2")

mean_alpha = mean_cor[4,1]
mean_beta = mean_cor[5,2]
mean_lambda = mean_cor[6,3]


q5_cor = matrix(correlation_nort $summary("correlation_matrix") %>% .$q5, byrow = T, nrow = 6)
colnames(q5_cor) = c("alpha_ses1","beta_ses1","lambda_ses1","alpha_ses2","beta_ses2","lambda_ses2")
rownames(q5_cor) = c("alpha_ses1","beta_ses1","lambda_ses1","alpha_ses2","beta_ses2","lambda_ses2")

q5_alpha = q5_cor[4,1]
q5_beta = q5_cor[5,2]
q5_lambda = q5_cor[6,3]

q95_cor = matrix(correlation_nort $summary("correlation_matrix") %>% .$q95, byrow = T, nrow = 6)
colnames(q95_cor) = c("alpha_ses1","beta_ses1","lambda_ses1","alpha_ses2","beta_ses2","lambda_ses2")
rownames(q95_cor) = c("alpha_ses1","beta_ses1","lambda_ses1","alpha_ses2","beta_ses2","lambda_ses2")

q95_alpha = q95_cor[4,1]
q95_beta = q95_cor[5,2]
q95_lambda = q95_cor[6,3]

get_text = function(mean,q5,q95){
  paste0(sprintf("%.2f",round(mean,2)), " [", sprintf("%.2f",round(q5,2)), " ; ",sprintf("%.2f",round(q95,2)), "]")
}

ddq = data.frame(variable = c("alpha","beta","lambda"),
                 text = c(get_text(mean_alpha,  q5_alpha, q95_alpha),
                   get_text(mean_beta,  q5_beta, q95_beta),
                   get_text(mean_lambda,  q5_lambda, q95_lambda)))%>% 
  mutate(propergated_uncertainty = TRUE, lapse = T, model = "Binary", structure = "Hierarchical")
```

#Write stuff for power analysis:
```{r}
# write.csv(a, here::here("realshit","Legrand reanalysis","savedcsv", "correlation matrix.csv"))
# 
# 
# means = fit$summary("gm") %>% .$mean
# 
# write.csv(means, here::here("realshit","Legrand reanalysis","savedcsv", "means.csv"))
# 
# between_variance = fit$summary("tau_u") %>% .$mean
# 
# write.csv(between_variance, here::here("realshit","Legrand reanalysis","savedcsv", "between_variance.csv"))



```


```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

```

## Visualize RT
```{r, fig.height=7, fig.width=7}
ss = "7"

psycho = hrd %>% filter(s == ss) %>% 
  mutate(session = as.factor(session), y1 = y/n) %>% 
  ggplot(aes(x = x, y = y1, col = session))+
  geom_point()+geom_smooth(method=glm, method.args= list(family = binomial(logit)), 
              se = FALSE)

RTS = hrd %>% filter(s == ss) %>% 
  mutate(session = as.factor(session), y1 = y/n) %>% 
  ggplot(aes(x = x, y = RT, col = session))+
  geom_point()+geom_smooth()

library(patchwork)
psycho/RTS
```


## Fit RT (single hierarchical)
```{r, fig.height=7, fig.width=12}
mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","test retest reaction time.stan"))


df = hrd


datastan = list(Y = cbind(df %>% filter(session == 1) %>% .$y, df %>% filter(session == 2) %>% .$y),
                N = nrow(df),
                RT = cbind(df %>% filter(session == 1) %>% .$RT, df %>% filter(session == 2) %>% .$RT),
                N_s1 = nrow(df %>% filter(session == 1)),
                N_s2 = nrow(df %>% filter(session == 2)),
                C = 2,
                
                min_RT = cbind(df %>% filter(session == 1) %>% group_by(s) %>% dplyr::summarize(min = min(RT)) %>% .$min,
                               df %>% filter(session == 2) %>% group_by(s) %>% dplyr::summarize(min = min(RT)) %>% .$min),
                
                S = length(unique(df$s)),
                S_id = cbind(df %>% filter(session == 1) %>% .$s, df %>% filter(session == 2) %>% .$s),
                X =  cbind(df %>% filter(session == 1) %>% .$x, df %>% filter(session == 2) %>% .$x))

# 
# correlation_rt_real_biggest_hier  <- mod$sample(
#   data = datastan, 
#   iter_sampling = 1000,
#   iter_warmup = 1000,
#   chains = 4, 
#   parallel_chains = 4,
#   refresh = 50,
#   adapt_delta = 0.90,
#   max_treedepth = 10
# )
# 

#correlation_rt_real_biggest_hier $save_object(here::here("realshit","Legrand reanalysis","workspace","correlation_rt_real_biggest_hier.RDS"))
correlation_rt_real_biggest_hier <- readRDS(here::here("realshit","Legrand reanalysis","workspace","correlation_rt_real_biggest_hier.RDS"))

get_session_cor = function(var){
  if(var == "mean"){
    a = matrix(correlation_rt_real_biggest_hier $summary("correlation_matrix") %>% .$mean, nrow = 14, byrow = TRUE)
  }else if(var == "q5"){
    a = matrix(correlation_rt_real_biggest_hier $summary("correlation_matrix") %>% .$q5, nrow = 14, byrow = TRUE)
  }else{
    a = matrix(correlation_rt_real_biggest_hier $summary("correlation_matrix") %>% .$q95, nrow = 14, byrow = TRUE)
  }
  cor_mean = c()
  for(i in 1:7){
    cor_mean[i] = a[i,i+7]
  }
  return(cor_mean)
}


mean = get_session_cor(var = "mean")
q5 = get_session_cor(var = "q5")
q95 = get_session_cor(var = "q95")

get_text = function(mean,q5,q95){
  paste0(sprintf("%.2f",round(mean,2)), " [", sprintf("%.2f",round(q5,2)), " ; ",sprintf("%.2f",round(q95,2)), "]")
}

get_text(mean,q5,q95)

ddq_rt = data.frame(variable = c("alpha","beta","lambda","intercept","betart","sigma","ndt"),
                 text = get_text(mean,  q5, q95))%>% 
  mutate(propergated_uncertainty = TRUE, lapse = T, model = "RT", structure = "Hierarchical")
```

#things for power analysis
```{r, fig.height=7, fig.width=12}
a = matrix(correlation_rt_real_biggest_hier $summary("correlation_matrix") %>% .$mean, nrow = 14, byrow = TRUE)

write.csv(a, here::here("realshit","Power analysis","pathfinder","reaction time","Legrand reults", "correlation matrix.csv"))


means = correlation_rt_real_biggest_hier$summary("gm") %>% .$mean

write.csv(means, here::here("realshit","Power analysis","pathfinder","reaction time","Legrand reults", "means.csv"))

between_variance = correlation_rt_real_biggest_hier$summary("tau_u") %>% .$mean

write.csv(between_variance, here::here("realshit","Power analysis","pathfinder","reaction time","Legrand reults", "between_variance.csv"))

```

# full model no ICC
```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","test retest full.stan"))

df = hrd

df = df %>% mutate(Confidence = ifelse(Confidence == 0, 0.01, ifelse(Confidence == 100, 0.99, Confidence/100))) %>% drop_na()
    

datastan = list(Y = cbind(df %>% filter(session == 1) %>% .$y, df %>% filter(session == 2) %>% .$y),
                N = nrow(df),
                RT = cbind(df %>% filter(session == 1) %>% .$RT, df %>% filter(session == 2) %>% .$RT),
                conf = cbind(df %>% filter(session == 1) %>% .$Confidence, df %>% filter(session == 2) %>% .$Confidence),
                N_s1 = nrow(df %>% filter(session == 1)),
                N_s2 = nrow(df %>% filter(session == 2)),
                C = 2,
                min_RT = cbind(df %>% filter(session == 1) %>% group_by(s) %>% dplyr::summarize(min = min(RT)) %>% .$min,
                               df %>% filter(session == 2) %>% group_by(s) %>% dplyr::summarize(min = min(RT)) %>% .$min),
                
                S = length(unique(df$s)),
                S_id = cbind(df %>% filter(session == 1) %>% .$s, df %>% filter(session == 2) %>% .$s),
                X =  cbind(df %>% filter(session == 1) %>% .$x, df %>% filter(session == 2) %>% .$x))



# full  <- mod$sample(
#   data = datastan,
#   iter_sampling = 1000,
#   iter_warmup = 1000,
#   chains = 4,
#   parallel_chains = 4,
#   refresh = 50,
#   adapt_delta = 0.90,
#   max_treedepth = 10
# )
#  

#full$save_object(here::here("realshit","Legrand reanalysis","workspace","full_rt.RDS"))
full_rt <- readRDS(here::here("realshit","Legrand reanalysis","workspace","full_rt.RDS"))

get_session_cor = function(var){
  if(var == "mean"){
    a = matrix(full_rt $summary("correlation_matrix") %>% .$mean, nrow = 20, byrow = TRUE)
  }else if(var == "q5"){
    a = matrix(full_rt $summary("correlation_matrix") %>% .$q5, nrow = 20, byrow = TRUE)
  }else{
    a = matrix(full_rt $summary("correlation_matrix") %>% .$q95, nrow = 20, byrow = TRUE)
  }
  cor_mean = c()
  for(i in 1:10){
    cor_mean[i] = a[i,i+10]
  }
  return(cor_mean)
}

mean = get_session_cor(var = "mean")
q5 = get_session_cor(var = "q5")
q95 = get_session_cor(var = "q95")

get_text = function(mean,q5,q95){
  paste0(sprintf("%.2f",round(mean,2)), " [", sprintf("%.2f",round(q5,2)), " ; ",sprintf("%.2f",round(q95,2)), "]")
}

get_text(mean,q5,q95)

ddq_full = data.frame(variable = c("alpha","beta","lambda","intercept","betart","sigma","ndt","intercept_conf","beta_conf","sigma_conf"),
                 text = get_text(mean,  q5, q95))%>% 
  mutate(propergated_uncertainty = TRUE, lapse = T, model = "RT+Conf", structure = "Hierarchical")
```


#correlation matrix
```{r}
mean = matrix(full$summary("correlation_matrix") %>% .$mean, nrow = 20, byrow = TRUE)

q5 = matrix(full$summary("correlation_matrix") %>% .$q5, nrow = 20, byrow = TRUE)

q95 = matrix(full$summary("correlation_matrix") %>% .$q95, nrow = 20, byrow = TRUE)

```


```{r}
rbind(d1,d2,d3,d4,d5,d6) %>% filter(variable %in% c("alpha","beta"))

rbind(ddq_full,ddq_rt,ddq) %>% filter(variable %in% c("alpha","beta"))
```


# ICC's

## Get data nort
```{r}
source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)
```


## Fit nort ICC
```{r}
mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","ICC","ICC_nort.stan"))

df = hrd

df = df %>% arrange(s,session) 

trials_per_subject_per_session = df %>% group_by(session,s) %>% summarize(n = n()) %>% .$n

cols_in_x = max(trials_per_subject_per_session)

P = length(unique(df$s))
S = length(unique(df$session))



X = array(NA , dim =  c(S*P,cols_in_x))
Y = array(NA , dim =  c(S*P,cols_in_x))

idx = NULL
for(ses in 1:S){
  for(p in 1:P){
    df1 = df %>% filter(s == p & session == ses)
    X[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$x
    Y[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$y
  }
}

X[is.na(X)] = 99
Y[is.na(Y)] = 99


datastan = list(Y = Y,
                N_s1 = max(df %>% filter(session == 1) %>% group_by(s) %>% summarize(n = n()) %>% .$n),
                N_s2 = max(df %>% filter(session == 2) %>% group_by(s) %>% summarize(n = n()) %>% .$n),
                S = length(unique(df$session)),
                P = length(unique(df$s)),
                t_p_s_p_ses = trials_per_subject_per_session,
                #npx = cbind(df %>% filter(session == 1) %>% .$n, df %>% filter(session == 2) %>% .$n),
                
                #S_id = cbind(df %>% filter(session == 1) %>% .$s, df %>% filter(session == 2) %>% .$s),
                X =  X
                )
                  
#                   
# fit <- mod$sample(
#   data = datastan, 
#   iter_sampling = 1000,
#   iter_warmup = 1000,
#   chains = 4, 
#   seed = 123,
#   parallel_chains = 4,
#   refresh = 10,
#   adapt_delta = 0.90,
#   max_treedepth = 12,
# )

#fit$save_object(here::here("realshit","Legrand reanalysis","ICC","workspace","ICC_nort_new.RDS"))


fit <- readRDS(here::here("realshit","Legrand reanalysis","ICC","workspace","ICC_nort_new.RDS"))


get_correlation = function(fit,parameter){
  
  ses1 = fit$summary(parameter)[1:187,]
  
  ses2 = fit$summary(parameter)[188:374,]
  
  return(cor.test(ses1$mean,ses2$mean))

}


get_correlation_unc = function(fit,parameter){
  
  df1 = as_draws_df(fit$draws(parameter))[,1:187]

  df2 = as_draws_df(fit$draws(parameter))[,188:374] 

  cor = c()
  for(i in 1:4000){
    cor[i] = cor.test(as.numeric(df1[i,]),as.numeric(df2[i,]))$estimate[[1]]
  }  

  return(cor)

}

cor_noun_alpha = get_correlation(fit,"psyalpha")
cor_noun_beta = get_correlation(fit,"psybeta")
cor_noun_lapse = get_correlation(fit,"lapse")

cor_unc_alpha = get_correlation_unc(fit,"psyalpha")
cor_unc_beta = get_correlation_unc(fit,"psybeta")
cor_unc_lapse = get_correlation_unc(fit,"lapse")

HDInterval::hdi(cor_unc_alpha)
HDInterval::hdi(cor_unc_beta)
HDInterval::hdi(cor_unc_lapse)


make_table_noun = function(cor){
  paste0(sprintf("%.2f",round(cor$estimate[[1]],2)), " [", sprintf("%.2f",round(cor$conf.int[[1]],2)), " ; ",sprintf("%.2f",round(cor$conf.int[[2]],2)), "]")
  
}


make_table_unc = function(cor){
  paste0(sprintf("%.2f",round(mean(cor),2)), " [", sprintf("%.2f",round(HDInterval::hdi(cor)[[1]],2)), " ; ",sprintf("%.2f",round(HDInterval::hdi(cor)[[2]],2)), "]")
  
}



icc1 = rbind(data.frame(variable = "alpha", text = make_table_noun(cor_noun_alpha)),
      data.frame(variable = "beta", text = make_table_noun(cor_noun_beta)),
      data.frame(variable = "lapse", text = make_table_noun(cor_noun_lapse))) %>% 
  mutate(propergated_uncertainty = FALSE, lapse = T, model = "Binary", structure = "Nested Hierarchical")


icc2 = rbind(data.frame(variable = "alpha", text = make_table_unc(cor_unc_alpha)),
      data.frame(variable = "beta", text = make_table_unc(cor_unc_beta)),
      data.frame(variable = "lapse", text = make_table_unc(cor_unc_lapse)))%>% 
  mutate(propergated_uncertainty = TRUE, lapse = T, model = "Binary", structure = "Nested Hierarchical")


ICC = rbind(icc1,icc2)

```


# ICC RT:

## Fit RT ICC
```{r, fig.height=10, fig.width=7}

source(here::here("realshit","Legrand reanalysis","legrand_scripts.R"))

hrd = get_data_rt(rt_threshold_s = 0.1)

mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","ICC","ICC_rt.stan"))

df = hrd

df = df %>% arrange(s,session)

min_RT = df %>% group_by(session,s) %>% summarize(min_RT = min(RT)) %>% .$min_RT


trials_per_subject_per_session = df %>% group_by(session,s) %>% summarize(n = n()) %>% .$n

cols_in_x = max(trials_per_subject_per_session)

P = length(unique(df$s))
S = length(unique(df$session))


X = array(NA , dim =  c(S*P,cols_in_x))
Y = array(NA , dim =  c(S*P,cols_in_x))
RT = array(NA , dim =  c(S*P,cols_in_x))

idx = NULL
for(ses in 1:S){
  for(p in 1:P){
    df1 = df %>% filter(s == p & session == ses)
    X[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$x
    Y[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$y
    RT[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$RT

      }
}

X[is.na(X)] = 99
Y[is.na(Y)] = 99
RT[is.na(RT)] = 99

datastan = list(Y = Y,
                N_s1 = max(df %>% filter(session == 1) %>% group_by(s) %>% summarize(n = n()) %>% .$n),
                N_s2 = max(df %>% filter(session == 2) %>% group_by(s) %>% summarize(n = n()) %>% .$n),
                S = length(unique(df$session)),
                P = length(unique(df$s)),
                t_p_s_p_ses = trials_per_subject_per_session,
                RT = RT,
                min_RT = min_RT,
                #npx = cbind(df %>% filter(session == 1) %>% .$n, df %>% filter(session == 2) %>% .$n),
                
                #S_id = cbind(df %>% filter(session == 1) %>% .$s, df %>% filter(session == 2) %>% .$s),
                X =  X
                )

# fit_RT <- mod$sample(
#   data = datastan, 
#   iter_sampling = 1000,
#   iter_warmup = 1000,
#   chains = 4, 
#   parallel_chains = 4,
#   refresh = 10,
#   adapt_delta = 0.90,
#   max_treedepth = 12,
# )
#

#ICC_RT$summary("ICC")

#fit_RT$save_object(here::here("realshit","Legrand reanalysis","ICC","workspace","ICC_RT.RDS"))

fit_RT <- readRDS(here::here("realshit","Legrand reanalysis","ICC","workspace","ICC_RT.RDS"))


cor_noun_alpha = get_correlation(fit_RT,"psyalpha")
cor_noun_beta = get_correlation(fit_RT,"psybeta")
cor_noun_lapse = get_correlation(fit_RT,"lapse")
cor_noun_intercept = get_correlation(fit_RT,"intercept")
cor_noun_betart = get_correlation(fit_RT,"beta")
cor_noun_sigma = get_correlation(fit_RT,"sigma")
cor_noun_ndt = get_correlation(fit_RT,"ndt")

cor_unc_alpha = get_correlation_unc(fit_RT,"psyalpha")
cor_unc_beta = get_correlation_unc(fit_RT,"psybeta")
cor_unc_lapse = get_correlation_unc(fit_RT,"lapse")
cor_unc_intercept = get_correlation_unc(fit_RT,"intercept")
cor_unc_betart = get_correlation_unc(fit_RT,"beta")
cor_unc_sigma = get_correlation_unc(fit_RT,"sigma")
cor_unc_ndt = get_correlation_unc(fit_RT,"ndt")


ICC_rt1 = rbind(data.frame(variable = "alpha", text = make_table_noun(cor_noun_alpha)),
      data.frame(variable = "beta", text = make_table_noun(cor_noun_beta)),
      data.frame(variable = "lapse", text = make_table_noun(cor_noun_lapse)),
      data.frame(variable = "intercept", text = make_table_noun(cor_noun_intercept)),
      data.frame(variable = "betart", text = make_table_noun(cor_noun_betart)),
      data.frame(variable = "sigma", text = make_table_noun(cor_noun_sigma)),
      data.frame(variable = "ndt", text = make_table_noun(cor_noun_ndt)))%>% 
  mutate(propergated_uncertainty = FALSE, lapse = T, model = "RT", structure = "Nested Hierarchical")






ICC_rt2 = rbind(data.frame(variable = "alpha", text = make_table_unc(cor_unc_alpha)),
      data.frame(variable = "beta", text = make_table_unc(cor_unc_beta)),
      data.frame(variable = "lapse", text = make_table_unc(cor_unc_lapse)),
      data.frame(variable = "intercept", text = make_table_unc(cor_unc_intercept)),
      data.frame(variable = "betart", text = make_table_unc(cor_unc_betart)),
      data.frame(variable = "sigma", text = make_table_unc(cor_unc_sigma)),
      data.frame(variable = "ndt", text = make_table_unc(cor_unc_ndt))) %>% 
    mutate(propergated_uncertainty = T, lapse = T, model = "RT", structure = "Nested Hierarchical")

ICC_rt = rbind(ICC_rt1,ICC_rt2)

```


#ICC FULL
```{r, fig.height=10, fig.width=7}
mod = cmdstanr::cmdstan_model(here::here("realshit","Legrand reanalysis","ICC","ICC_full.stan"))


df = hrd

df = df %>% mutate(Confidence = ifelse(Confidence == 0, 0.01, ifelse(Confidence == 100, 0.99, Confidence/100))) %>% drop_na()

df = df %>% arrange(s,session)

min_RT = df %>% group_by(session,s) %>% summarize(min_RT = min(RT)) %>% .$min_RT


trials_per_subject_per_session = df %>% group_by(session,s) %>% summarize(n = n()) %>% .$n

cols_in_x = max(trials_per_subject_per_session)

P = length(unique(df$s))
S = length(unique(df$session))


X = array(NA , dim =  c(S*P,cols_in_x))
Y = array(NA , dim =  c(S*P,cols_in_x))
RT = array(NA , dim =  c(S*P,cols_in_x))
conf = array(NA , dim =  c(S*P,cols_in_x))

idx = NULL
for(ses in 1:S){
  for(p in 1:P){
    df1 = df %>% filter(s == p & session == ses)
    X[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$x
    Y[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$y
    RT[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$RT
    conf[(ses-1)*P+p, 1:trials_per_subject_per_session[(ses-1)*P+p]] = df1$Confidence

      }
}

X[is.na(X)] = 99
Y[is.na(Y)] = 99
RT[is.na(RT)] = 99
conf[is.na(conf)] = 2

datastan = list(Y = Y,
                N_s1 = max(df %>% filter(session == 1) %>% group_by(s) %>% summarize(n = n()) %>% .$n),
                N_s2 = max(df %>% filter(session == 2) %>% group_by(s) %>% summarize(n = n()) %>% .$n),
                S = length(unique(df$session)),
                P = length(unique(df$s)),
                t_p_s_p_ses = trials_per_subject_per_session,
                RT = RT,
                conf = conf,
                min_RT = min_RT,
                #npx = cbind(df %>% filter(session == 1) %>% .$n, df %>% filter(session == 2) %>% .$n),
                
                #S_id = cbind(df %>% filter(session == 1) %>% .$s, df %>% filter(session == 2) %>% .$s),
                X =  X
                )
# 
# fit_full <- mod$sample(
#   data = datastan, 
#   iter_sampling = 1000,
#   iter_warmup = 1000,
#   chains = 4, 
#   parallel_chains = 4,
#   refresh = 10,
#   init = 0,
#   adapt_delta = 0.80,
#   max_treedepth = 12,
# )
# #

#ICC_RT$summary("ICC")

# fit_full$save_object(here::here("realshit","Legrand reanalysis","ICC","workspace","ICC_full.RDS"))

ICC_full <- readRDS(here::here("realshit","Legrand reanalysis","ICC","workspace","ICC_full.RDS"))


cor_noun_alpha = get_correlation(ICC_full,"psyalpha")
cor_noun_beta = get_correlation(ICC_full,"psybeta")
cor_noun_lapse = get_correlation(ICC_full,"lapse")
cor_noun_intercept = get_correlation(ICC_full,"intercept")
cor_noun_betart = get_correlation(ICC_full,"beta")
cor_noun_sigma = get_correlation(ICC_full,"sigma")
cor_noun_ndt = get_correlation(ICC_full,"ndt")
cor_noun_conf_int = get_correlation(ICC_full,"intercept_conf")
cor_noun_beta_conf = get_correlation(ICC_full,"beta_conf")
cor_noun_sigma_conf = get_correlation(ICC_full,"sigma_conf")



cor_unc_alpha = get_correlation_unc(ICC_full,"psyalpha")
cor_unc_beta = get_correlation_unc(ICC_full,"psybeta")
cor_unc_lapse = get_correlation_unc(ICC_full,"lapse")
cor_unc_intercept = get_correlation_unc(ICC_full,"intercept")
cor_unc_betart = get_correlation_unc(ICC_full,"beta")
cor_unc_sigma = get_correlation_unc(ICC_full,"sigma")
cor_unc_ndt = get_correlation_unc(ICC_full,"ndt")
cor_unc_conf_int = get_correlation_unc(ICC_full,"intercept_conf")
cor_unc_beta_conf = get_correlation_unc(ICC_full,"beta_conf")
cor_unc_sigma_conf = get_correlation_unc(ICC_full,"sigma_conf")


ICC_full1 = rbind(data.frame(variable = "alpha", text = make_table_noun(cor_noun_alpha)),
      data.frame(variable = "beta", text = make_table_noun(cor_noun_beta)),
      data.frame(variable = "lapse", text = make_table_noun(cor_noun_lapse)),
      data.frame(variable = "intercept", text = make_table_noun(cor_noun_intercept)),
      data.frame(variable = "betart", text = make_table_noun(cor_noun_betart)),
      data.frame(variable = "sigma", text = make_table_noun(cor_noun_sigma)),
      data.frame(variable = "ndt", text = make_table_noun(cor_noun_ndt)),
      data.frame(variable = "conf_int", text = make_table_noun(cor_noun_conf_int)),
      data.frame(variable = "beta_conf", text = make_table_noun(cor_noun_beta_conf)),
      data.frame(variable = "sigma_conf", text = make_table_noun(cor_noun_sigma_conf)))%>% 
  mutate(propergated_uncertainty = FALSE, lapse = T, model = "RT+Conf", structure = "Nested Hierarchical")



ICC_full2 = rbind(data.frame(variable = "alpha", text = make_table_unc(cor_unc_alpha)),
      data.frame(variable = "beta", text = make_table_unc(cor_unc_beta)),
      data.frame(variable = "lapse", text = make_table_unc(cor_unc_lapse)),
      data.frame(variable = "intercept", text = make_table_unc(cor_unc_intercept)),
      data.frame(variable = "betart", text = make_table_unc(cor_unc_betart)),
      data.frame(variable = "sigma", text = make_table_unc(cor_unc_sigma)),
      data.frame(variable = "ndt", text = make_table_unc(cor_unc_ndt)),
      data.frame(variable = "conf_int", text = make_table_unc(cor_unc_conf_int)),
      data.frame(variable = "beta_conf", text = make_table_unc(cor_unc_beta_conf)),
      data.frame(variable = "sigma_conf", text = make_table_unc(cor_unc_sigma_conf))) %>% 
    mutate(propergated_uncertainty = TRUE, lapse = T, model = "RT+Conf", structure = "Nested Hierarchical")


ICC_full = rbind(ICC_full1,ICC_full2)

```




```{r}

d = rbind(
  rbind(d1,d2,d3,d4,d5,d6),
  rbind(ddq_full,ddq_rt,ddq),
  rbind(ICC, ICC_rt, ICC_full)
)%>% filter(variable %in% c("alpha", "beta") & propergated_uncertainty == TRUE)


d$model = as.factor(d$model)
d$structure = as.factor(d$structure)

levels(d$model)
levels(d$structure)

d$structure <- factor(d$structure, levels = c("Single","Hierarchical","Nested Hierarchical"))

d$text <- as.character(d$text)

d

table = d %>% arrange(structure,model,lapse) %>% mutate(propergated_uncertainty = NULL) %>% pivot_wider(names_from = "variable",values_from = "text") %>% 
  select(alpha,beta,lapse,model,structure)

library(flextable)


write.csv(table, file = here::here("table3.csv"))

flextable::flextable(table) %>% width(1:2, width = 1.5)
```

