## *Adaptive design optimization*

An import consideration of the parameter recovery described above, is what the design of the experiment that the simulated agent goes through. Looking back at figure 6 providing stimulus values in the far ends of the psychometric functions i.e. in the ranges of [-50 ; -25] and [25 ; 50] will in most cases, for most agents, give next to no information on the shape of the psychometric and therefore the parameters we mostly care about i.e. the threshold and slope, see supplementary note 2 for the lapse rate. On average the agents’ psychometric functions are monotonically increasing in the interval of [-25 ; 25]. Therefore, selecting stimuli (inputs) in this interval must be better for decreasing the estimation uncertainty in the two parameters that are most often interpreted, compared to randomly or uniformly exploring the input space. one might even go a step further and instead of selecting inputs that are more appropriate for the mean of the population, one could individualize each experiment to the participant. This practice of individualizing the experiment of interest is called adaptive design optimization (ADO) and revolves around selecting inputs that are optimal given a specific criterion [@watson_quest_2017; @prins_psi-marginal_2013]. Many of these criterions exists such as minimizing entropy, minimizing the posterior variance or mutual information, but what they all have in common is that they decrease estimation uncertainty of either all or certain parameters to a meaningful degree. One of the main challenges of utilizing ADO is that because the experiment is updated and individualized on a trial by trial basis the algorithm determining the next stimulus must run in tandem with the experiment. This puts quite a high constraint on computation time of the algorithm. This particular issue has partly been solved in the existing packages calculating a grid of a particular resolution of parameter values at at a trial and then using the optimization stategy to find the next optimal stimulus value. This clever solution puts the heavy computation time before the experiment and ensures that when the experiment is run only a single look up is needed to provide the next stimulus value on each trial. This approach works great for psychophysical experiments or other experiments where each trial is independent of the next. This is because only a single optimization step is required for each trial, whereas if trials were mutually dependent as in a learning experiment, then the algorithm would need to calculate all possible lines of stimuli and responses until a certain point which given the combinatorics can become a daunting task.

In order to keep coherence with the rest of the thesis, I will demonstrate how leveraging the single-fit model designed for conducting the simple single-subject parameter recovery can used together with the understanding of informative stimulus values described above to make a custom ADO algorithm. The advantages of being able to write such a custom algorithms is two-fold. Firstly, as long as the model can be written to invert observed data to parameter values (i.e. fit to data), then it can also be used to simulate stimulus values, this therefore increases the flexibility in model selection. Secondly, as this approach is not optimial for stimulus selection the method can even be extended to mutually dependent experiments. Illustrating this approach can be done by using variational inference algorithms that can quickly estimate an approximate posterior distribution of the parameters of interest, in this particular thesis the pathfinder algorithms implemted in Rstan is used [@zhang_pathfinder_2022]. The rationale behind this approach to ADO is to iteratively fit the model as responses from the participant is collected, the parameter estimates of the model is then updated and a new stimulus value is then selected based on these estimates and the knowledge of which stimulus values are the most informative for particular parameter values. For a full description of how the pathfinder algorithm was implemented, see supplementary note 3.

Figure 10 shows how the posterior distribution of the 3 parameters of the PF varies as a function of trials in both the previously used uniform selection and implemented pathfinder approach. As can be seen both approaches makes the parameters converge towards the real simulated values (black line), however the speed at which this happens is different, especially for the two parameters that the pathfinder algorithm is optimizing for i.e. $\alpha$ and $\beta$. For these two parameters after just 20 trials using the pathfinder optimization has found the simulated parameter value and decreased the estimation uncertainty (posterior variance), whereas even after 50 trials the uniform approach still has a bit of a bias in the estimation, the individual points are not on the black line, but also a substantial estimation uncertainty associated with it. For completeness a PSI-algorithm was also used, in order to compare the feasibility in this new approach due to high constraint on computation time of the algorithm [@kontsevich_bayesian_1999]. Interestingly the pathfinder algorithm ran in 14 seconds for the 50 trials whereas the PSI algorithm ran in 30 seconds. This highlights the feasibility of this approach as experimental designs have to be able to run relatively quickly, in order to keep the attention of the subject [@kwon_adaptive_2023].

<!-- pathfinder vs psi vs uniform plot -->
```{r figure 10, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "**Figure 10 comparison of algorithms to obtain stimulus values of the psychometric function** "}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","Pathfinder.PNG")), scale = 1)
```

To show the differences in these ways of selecting stimulus values across a range of trial numbers, the Pathfinder, Uniform and PSI algorithms were run 100 times for trials ranging from 20 to 100 in a sequence of 10 trials (using the same range of parameter values as depicted in table 1). In order to make the comparison as fair as possible each of the algorithms were only used to generate the stimulus sequence, meaning that all datasets were refitted using the same single fit Bayesian model for the final estimate that was compared to the simulated value, the same model used for conducting the single subject parameter recovery. For complete details on the fitting and optimization strategy see supplementary material note 3 and 4, as well as prior initalization for PSI and Pathfinder. Figure 11 shows the results of this simulation with the top panel showing the bias, i.e. the difference between the estimated and simulated parameter values and the bottom panel the uncertainty in the estimated parameter value.


<!-- pathfinder vs psi vs uniform plot over many iterations-->
```{r figure 11, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "**Figure 11.** shows how the estimation uncertainty and bias changes according to the number of trials and parameter value estimated with the different methods. "}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","Pathfinder_bias_estimation.PNG")), scale = 1)


```


Having tested and compared this this pathfinder algorithm, it is now possible to examine three other focal points of minimizing estimation uncertainty in the parameter values, i.e. subjects, trials and the influence on the mean simulated slope value. The last point is less obvious than the two others but stems from the fact that increasing the slope (decreasing the steepness) of the Psychometric function will make it harder to estimate all the parameters of the function i.e. the estimation uncertainty is increased if other factors are held constant, the reason for this will become clear below. 

For this purpose, trials ranging from 20 to 200 in increments of 20, subjects being between 10, 30 and 50 and lastly mean slope values of 1,2 and 3 in the unconstrained space are simulated, with all other parameter values being identical to table 1. To guard against simulations that are not representative due to either bad convergences in the ADO or in the fitting procedure, each combination was run 5 times. Figure 12 displays the result of this parameter recovery across trials and group mean slope levels  (i.e. simulated beta values). Figure 12 only displays the correlational approach with inclusion of estimation uncertainty in the upper panel and the develop $ICC_2$ in the lower panel, for the two other metrics i.e. the correlational approach without estimation uncertainty and the $\ICC_1$ see supplementary figure 3. Due to the limited influence of subjects these have been aggregated, Supplementary figure 4 displays the individual subject simulations.
 
<!-- make or break plots of ICC vs correlation coefficient for pathfinder  -->
```{r figure 12, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "**Figure 12 comparison of parameter recovery metrics.** First row depicts how the estimate of the correlation coefficent between simulated and estimated means change as a function of trials (x-axis) and the simulated mean slope (color) for each parameter of the psychometric function (columns). The bottom row shows how the estimate of $ICC_2$ changes based on the same metrics as the correlation coefficient. Note that the correlation coeffecient has been uncertainty propergated using bootstrapping."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","ICC_vs_correlation.PNG")), scale = 1)
```


<!-- Some thought about the plots and modeling opportunities: -->
The main differences between the two approaches is that the ICC metric is generally lower than the correlational approach, but both aympotitically move towards one with increasing trials and or simulated mean slopes of the psychometric function. One way to hightlight the difference and the meaning of these difference is to plot the pairwise scatter plot of simulated vs recovered parameter estimates. These pairwise parameter estimates are what both metrics in Figure 12 attempt to describe. Picking the instances where the difference between the correlational and ICC approach is the greatest will give insight to which metric might be more suitable. Figure 13 therefore shows the pairwise scatter plot of the threshold in three selected trials (40, 120 and 200) for both steep and shallow slopes (means of 1 and 3 respectively). These instances were choosen because the estimate of the correlation and ICC were similar for the steep slopes but remarkably different with shallower slopes of the psychometric function. Figure 13 clearly shows why there is such a difference between the two approaches, the ICC metric is penalized much more by the increased estimation uncertainty in the threshold of shallower slopes than the correlation coefficient. This observation indicates that the ICC metric is much more sensitive to the uncertainty of which it is calculated compared to the correlation approach. The same reasons apply for the difference in the slope estimate itself and pairwise scatter plots can be found in supplementary figure 6. Lastly both approaches suggest that the lapse rate is below the two other metrics without much improvement with increasing trials, but still with the ICC being more conservative. 

```{r figure 13, fig.width = 7.2, fig.height = 5, warning = F, message = F, echo = F, fig.cap = "**Figure 13.** Showing the pairwise scatter plots of simulated vs recovered threshold ($\\alpha$) parameter when the simulated beta value is low (beta = 1) and high (beta = 3) for subjects (rows) and trials (columns)."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","scatter_plot.PNG")), scale = 1)
```


As conveyed by the pairwise scatter plots in figure 13, the conservative ICC metric capture the fact that estimation uncertainty is a source of variability that can still be reduced even when the correlation coefficient might indicate close to perfect fit. This is exactly the behavior one would like to have when trying to understand their model as this information is much more sensitive, furthermore the values also have a natural interpretation in the case of ICC whereas for the correlation coefficient this is not straightforward. An ICC value of 0.8 means that 80% of the variance in the model is governed by the between subject level variance and only 20 % is in the estimation or test -retest uncertainty. The ICC could of cause be further decomposed into what proportion of variance of the 20% is from estimation and what is from test retest uncertainty, again see supplementary figure 3. This straightforward interpretation is not present for the correlation coefficient, especially because of the arguments laid forth in the “current problems with internal recovery” section. 

Another import considerations that has been deployed here which is sometimes neglected in parameter recovery analyses in the literature is the hierarchical structure [@hess_bayesian_2024; @hubner_improving_2020 @harrison_interoception_2021]. The distinction between fitting a hierarchical model and iteratively fitting single subject models are present in in the difference between the correlation coefficient estimates in figure 7 and 8. This again highlights some of the missed opportunities of understand the model, especially the model that is fit to the real data as hierarchical models are often fit in order to improve estimation of real data. Lastly what this approach also highlights is that parameter values in a cognitive model does not necessarily have to improve with increasing trials. This is the case for the lapse rate in this particular PF and could perhaps have been improved if the ADO algorithm was tuned to estimate this parameter. Therefore mindlessly increasing the number of trials to hopefully decrease estimation uncertainty on a parameter should be done after having conducted such an analysis in order to ensure that resources are not wasted trying to decrease estimation uncertainty, when its not possible. 



<!-- title again idjk -->
## **Increasing the information in the cognitive model**

In this section it will described how using data and or information about the underlying experiment or generative model, estimation uncertainty can be further reduced in the parameter estimates of interest. This is without a need for increasing trials or ensuring that the slope of the PF of the participants is steep, which was showed above to increase both metrics of parameter recovery. For the sake of this thesis, I will look at incorporating the reaction times of the agents’ responses as sources of information about the underlying psychometric function of their binary choices. I will be focusing on the reaction times as these have a long and rigorous history in the  cognitive science literature, but more importantly are present in many experiments conducted today [@sternberg_memory-scanning_1969; @pirolli_role_1985; @macleod_training_1988]. In order to incorporate the reactions times into the current formulation of the generative structure of the task, it is helpful to think of the output of PF as a probability of responding a particular value, say 1. This therefore entails that in either end of the tail of the PF the certainty with which you respond is the highest and the midpoint between the extremes (the threshold) is the most uncertain. This descriptive formulation is what the variance of the Bernoulli distribution describes:

$$
Var(Bern(p)) = p \cdot (1-p)
$$
Using this information together with the assumption that participants will respond slower when more uncertain and faster if certain the reactions times of each trial can be modeled as a linear combination of this Bernoulli variance. This linear combination would entail an intercept to account for the individual differences in mean reaction time and a slope that scales the influences of the uncertainty of the variances of the underlying PF i.e. the bernoulli variance:
$$
RT \sim intercept + \beta_{RT} * Var(Bern(p))
$$
where intercept represents the intercept and $\beta_{RT}$ represents the degree to which the uncertainty from the psychometric function influences the reaction times, see Figure 14 for a visualization of this mapping. In order to stochastically model the reaction times with this formulation a probability density function is needed to account for the noise observed. Due to the non negative nature of reactions times and the physical constraints of information processing (there is a delay from the time the stimulus is presented to which it reaches the brain of the agent), a sensible choice of this probability density function would be the shifted log normal distribution. This introduces two more variables, a non decision time ($\tau$) and a standard deviation ($\sigma$) for the log normal distribution [@ranger_modeling_2020; @jain_comparative_2015]. This formulation of the reactions times therefore follow the relationship described below, where the crucial link, linking the psychometric function and the reaction times being the bernoulli variance.

$$
RT \sim LogNormal(intercept + \beta_{RT} * Var(Bern(p), \sigma) + \tau
$$

To show how these reaction times help with recovery of the parameters of interest i.e. the threshold and slope of the PF, agents with the parameter values displayed in table 2 were simulated. 


To understand the influence of the size of coupling between the binary responses and the reaction times ($\beta_{RT}$) this parameter was simulated with either a high or low group mean, 1.5 and 1 respectively. The steepness of the slope of the PF was also varied between high and low1 and 3 respectively. Again, showing and understanding what these parameter values mean we simulate the parameters and display the behavior. This can be seen in figure 14 where 10 simulated subjects are visualized. The figure clearly shows the relationship between the PF and the reaction time function. In the high stimulus values i.e. the most extreme x-values the reaction times are fast and the psychometric function is approaching 0 or 1. As the PF increases from very low stimulus values (the left side), the reactions times increase upuntill the threshold for that agent is reached and then decreases. 


```{r Table 2, warning = F, message = F, echo = F, fig.cap = "**Table 2: Parameter distributions for reaction time simulations** Parameter distributions for the simulated agents and the transformations for each of the parameters when including the Reaction times in the psychometric function."}
table2 = read.csv(here::here("tables","table2.csv")) %>% mutate(X = NULL)

table2 = flextable::flextable(table2) %>% flextable::width(c(1), width = 1.3) %>% flextable::width(c(4), width = 1.8)
table2
```

```{r figure 14, fig.width = 7.2, fig.height = 5, warning = F, message = F, echo = F, fig.cap = "**Figure 14. Visualization of the psychometric function with Reaction times.** Upper panel depicts 10 psychometric functions where parameters were drawn from table2 (Beta = 3 and BetaRT = 1.5). Lower Panel depicts the assumed relationship between the stimulus value (x) and the reaction times (y), which as can be seen is dependent on the shape of the psychometric function in the upper panel. The reaction time functions peak around the psychometric threshold and tapers off when the psychometric function asympotes at 1 or 0."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","plot13_psychometric_RT.png")), scale = 1)
```

Next uterlizing this generative model a parameter recovery analysis can be conducted that investigates the influence of these reactions times on the recovery of the parameters of the PF. Here only the $ICC_1$ are depicted for the 8 combinations of slope, size of the coupling and inclusion of reaction time is depicted. Similar results were obtained by using the correlation coefficient, which can be seen in supplementary figure 7.

Figure 15 displays the difference in parameter recovery between including reaction times in the modeling or not, on the 3 parameters of the psychometric function. The plot firstly highlights increased $ICC_1$ values for the two parameters of particular interest i.e. the threshold (Alpha) and the slope (Beta). This difference seems to be present in the slope for both slope conditions (i.e. steep and shallow simulated mean slopes) but also in the shallow simulated slope (beta = 3) for the threshold where the $ICC_1$ metric has not reached its asympotete of 1 as in the steep slope simulation.



```{r Figure 15, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "Figure 15 histogram of the mean difference between the ICC value obtained from using the reaction times or not, colors display the simulated level of coupling between the underlying psychometric function and the reaction times. Stronger coupling is associated with bigger parameter recovery effects for both threshold and slope, but not lapse rate."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","ICC_rtplot.PNG")), scale = 1)
```


<!-- ```{r Figure141, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "Figure 141 histogram of the mean difference between the ICC value obtained from using the reaction times or not, colors display the simulated level of coupling between the underlying psychometric function and the reaction times. Stronger coupling is associated with bigger parameter recovery effects for both threshold and slope, but not lapse rate."} -->



<!-- cowplot::ggdraw() + -->
<!--     cowplot::draw_image(magick::image_read(here::here("Figures","ICC_rt_difplot.PNG")), scale = 1) -->


<!-- ``` -->



