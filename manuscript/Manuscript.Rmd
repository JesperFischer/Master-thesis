---
title: "Uncertainty In Cognitive Science"
author: Jesper Fischer Ehmsen,
output:
  word_document:
    reference_docx: Knitting files/docx_template.docx
  pdf_document:
    latex_engine: xelatex
  html_document: default
bibliography: [Knitting files/Master_thesis_refs.bib, Knitting files/packages.bib, Knitting files/rpackage.bib]
link-citations: yes
linkcolor: blue
csl: Knitting files/apa.csl
always_allow_html: yes
---


```{r load packages, warning = F, message = F, echo = F, include=FALSE}
knitr::opts_chunk$set(dpi=300)

# seed
set.seed(123)

# packages
if (!require("pacman")) install.packages("pacman")

packages_used = c("tidyverse", "here", "knitr","yaml", "cowplot","flextable", "correlation","cmdstanr","stats", "shiny")

knit = knitr::opts_knit$get("rmarkdown.pandoc.to")

knitr::write_bib(x = packages_used, file = here::here("manuscript","Knitting files","packages.bib"))

#pacman::p_load(c("tidyverse", "here", "knitr","yaml", "cowplot","flextabe", "correlation"))

lapply(packages_used, library, character.only = TRUE)

```

\newpage

# Summary

Understanding human cognition and behavior is the primary aim of Cognitive Science. To achieve this, quantitative methods are frequently used. When these quantitative methods are employed assumptions and simplifications must be made, which are embedded in the models used. This thesis explores some of these assumptions herein, propagation of uncertainty and validation of the models themselves, in a simulated settings. Uncertainty propagation stems from the fact that when quantitative data is collected uncertainty is embedded in these measurements. A failure to account for these uncertainties can have a substantial impact on the inferences made based on these measures. With a focus in how uncertainties in statistical and cognitive models propagate, the thesis will further investigate how the validation process of cognitive models can be improved, by embracing and quantifying the inevitable uncertainties associated with our cognitive models. The framework proposed revolves around simulating agents with known properties which are then fitted to the cognitive model to access the model's ability to detect these simulated properties
, while accounting for uncertainties embedded in these estimations. The thesis will explore these considerations through the three-parameter psychometric function, a widely used cognitive model.

It will be shown that a correlational approach to determine internal model validity is at best quite insensible compared to a more sophisticated approach based on the intra class coefficient. The thesis will then demonstrate how uncertainties in parameter estimates and in these two metrics can be minimized through more sophisticated methods. This will be done without a need for increasing the number of trials or subjects, which is the standard approach. In this regard the thesis highlights two important methods for minimizing uncertainty. Firstly, optimizing the design of the experiment such that each trial will contain the most information possible. Secondly, incorporating already collected data, such as reaction times, into the cognitive model as a means of decreasing the uncertainties in the measures of interest. The thesis goes on to explore and re-analyses published data using the psychometric function. Here it is demonstrated that incorporating structural assumptions of how the data was collected, as well as incorporating reaction times, does not only decrease uncertainty in the reliability, but also well describes the data. Lastly the thesis highlights and demonstrates novel opportunities for conducting power analyses using. Here it is demonstrated, based on the re-analysis of the published data, that by using simulations its possible to build predictive-models that accurately estimate the number of trials, subjects and effect-size needed for the psychometric function to find group differences in a particular parameter estimates. This highlights an avenue for researchers building cognitive models to inform others, about their models' strengths and weaknesses in estimating parameters of interest. Lastly with this novel way of generalizing power analyses it is shown that the number of trials in a cognitive science experiment is highly relevant in estimating the psychometric models ability to pick up on group differences in parameters, which is completely neglected by commonly used power analysis soft-wares.


\newpage

# Acknowledgement

part of the computation done for this project was performed on the UCloud interactive HPC system, which is managed by the eScience Center at the University of Southern Denmark. 

All scripts, code, models and simulated data can be found on the following [Github page](https://github.com/JesperFischer/Master-thesis). Here all analyses as well as the entire manuscript is documented. 

\newpage

```{r Introduction, child="1_Introduction.Rmd"}

```

<!-- \newpage -->

<!-- ```{r Measurement uncertainty_v2, child="2_Measurement uncertainty.Rmd"} -->

<!-- ``` -->

\newpage

```{r Modeling definitions, child="2_Modeling definitions.Rmd"}

```

\newpage

```{r uncertainty minimazation, child="3_uncertainty minimazation.Rmd"}

```

\newpage

```{r Real data, child="4_Real data.Rmd"}

```

\newpage

```{r Power analysis, child="5_Power analysis.Rmd"}

```

\newpage

```{r Discussion, child="6_Discussion.Rmd"}

```

\newpage

# References


::: {#refs}
:::

\newpage
```{r supplementary, child="Supplementary material/supplementary material.Rmd"}

```
