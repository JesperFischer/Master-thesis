
\newpage

# Supplementary material

## **Supplementary analysis 1**

As mentioned in the main text, introducing measurement uncertainty or any type of particular uncertainty into statistical metrics and easily be done by the use of bootstrapping / re-sampling. Here i will demonstrate an example from a simple linear regression analysis with 3 parameters an intercept, a slope and a residual variance. To do this we consider an idealized example of a fictional researcher wanting to understand the relationship between reaction times and stress while incorporating all types of uncertainty. To do this the researcher conducts an experiment where participants are measured several times under different conditions to introduce stress. In this example both of these measures have associated uncertainty, see the individual data points in the Supplementary analysis Figure 1. The relationship between reaction times and stress is determined by the slope of the regression line depicted in the Supplementary analysis Figure 1. Estimation uncertainty can thus be thought of as the uncertainty in the parameter estimates achieved by fitting a linear model to the data see the linear model in Supplementary analysis Figure 1. Finally test re-test  uncertainty can be thought as when the researchers study on reaction times and stress is tested twice on different days to understand how stable the relationship is over time.As the relationship is measured by the parameters of the model the stability of the relationship is measured by the stability of the parameters. One might imagine that the amount of sleep acquired before the experimental day could influence both measures of the task i.e. reaction time and susceptibility to stress and perhaps even their relationship. Supplementary analysis Figure 2 displays how the parameter estimates of the same model as presented in Supplementary analysis Figure 1 with and without accounting for uncertainty propagation change based on the propagation of uncertainty. As can be seen from Supplementary analysis Figure 1 accounting for the measurement uncertainty does not change much the prediction made by the model, however when propagating these extra uncertainties into the next analysis of the parameters i.e. from session to session in Supplementary analysis Figure 2 the change in results become more pronounced. The main effect for the current linear model is that the residual variance (sigma) and the intercept is underestimated without error propagation and the slope parameter is overestimated.

```{r supplementary_analysis_figure1, fig.width = 7, fig.height = 4, warning = F, message = F, echo = F, fig.cap = "**Supplementary analysis Figure 1: Measurement and Estimation uncertainty.** The figure displays a linear regression between two measurements of for instance reaction time and stress with measurement uncertainty depicted as vertical and horizontal error bars on individual points. The mean of the regression line with and without propagated uncertainty is highlighted in grey and dark green respectively. Lastly a prediction interval is depicted as the shaded area around the mean of the regression line with and without propagated uncertainty again in grey and green respectively. The difference between the green and grey lines are therefore the difference between accounting for measurement uncertainty and not accounting for it."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","figure_1_measurement_uncertainty.png")), scale = 1)
```



```{r supplementary_analysis_figure2, fig.width = 7, fig.height = 4, warning = F, message = F, echo = F, fig.cap = "**Supplementary analysis Figure 2, Test retest uncertainty.** Diplays the results of fitting the linear regression in Figure 1 twice, with and without accounting for measurement uncertainty. Each facet represents one of the three parameters of the linear model, the intercept the residual uncertainty (sigma) and the slope respectively from left to right. Colors represented weather the measurement uncertainty was proporgated or not."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","figure_2_test_retest.png")), scale = 1)
```



## **Supplementary Figures**

### Supplementary figure 1

```{r, fig.width=7.2, fig.height=5, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 1 Comparison of analytical and bootstrapping correlation coefficient.** Histograms of the difference between different metrics of the correlation coefficient when bootstrapping and analytically calculating the correlation coefficient. Facets shows the different used metrics when evaluating the correlation coefficient i.e. the mean, the 2% quantile and the 97% quantile. colors represent the sample size, i.e. the number of datapoints the simulated correlation coefficient was based on."}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure1.PNG")), scale = 1)

```

### Supplementary figure 2

```{r, fig.width=7.2, fig.height=5, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 2 Comparison of linear regression and correlation coefficient.** Scatter plot of the difference between the mean, quantile 2 and quantile 97 of the slope of a standardized linear regression and the correlation coefficient. Facets show the different statistical metric i.e. mean, q2 and q97 and the colors display the simulated correlation coefficient of the multinomial distribution. The x-axis is the number of datapoints simulated from the multinomial distribuion."}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure2.PNG")), scale = 1)

```
### Supplementary figure 3

```{r, fig.height=10, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 3 Parameter recovery of the psychometric function for all four parameter recovery metrics investigated.**"}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure3.PNG")), scale = 1)

```

### Supplementary figure 4

```{r, fig.height=10, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 3 Parameter recovery of the psychometric function for all four parameter recovery metrics investigated.**"}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure4.PNG")), scale = 1)

```

### Supplementary figure 5

```{r, fig.height=10, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 3 Parameter recovery of the psychometric function for all four parameter recovery metrics investigated.**"}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure5.PNG")), scale = 1)

```

### Supplementary figure 6

```{r, fig.height=5, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 3 Parameter recovery of the psychometric function for all four parameter recovery metrics investigated.**"}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure6.PNG")), scale = 1)

```



### Supplementary figure 7

```{r, fig.height=7.2, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 7. Parameter recovery of the psychometric function for the correlation coefficient for each parameter (columns) in each combination of including and not including rts and its size (color) and the simulated mean slope (rows) for differing number of trials x-axis.**"}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure7.PNG")), scale = 1)

```

### Supplementary figure 8

```{r, fig.height=7.2, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 8. Group level posterior predictive checks of the 3 types of responses, Confidence, binary (faster or slower) and reaction time on the binary response for the Nested Hierarchical model.** Facets represent the 3 types of responses, 0-1 Confidence ratings, 0 or 1 binary responses of (faster or slower) and the reaction time for these binary responses. Red line depicts the mean of the posterior and the blue lines represents 100 posterior draws."}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure8.PNG")), scale = 1)

```
### Supplementary figure 9

```{r, fig.height=7.2, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 8. Group level posterior predictive checks of the 3 types of responses, Confidence, binary (faster or slower) and reaction time on the binary response for the Nested Hierarchical model.** Facets represent the 3 types of responses, 0-1 Confidence ratings, 0 or 1 binary responses of (faster or slower) and the reaction time for these binary responses. Red line depicts the mean of the posterior and the blue lines represents 100 posterior draws."}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure9.PNG")), scale = 1)

```

### Supplementary figure 10

```{r, fig.height=7.2, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 8. Group level posterior predictive checks of the 3 types of responses, Confidence, binary (faster or slower) and reaction time on the binary response for the non-nested Hierarchical model.** Facets represent the 3 types of responses, 0-1 Confidence ratings, 0 or 1 binary responses of (faster or slower) and the reaction time for these binary responses. Red line depicts the mean of the posterior and the blue lines represents 100 posterior draws."}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure10.PNG")), scale = 1)

```

### Supplementary figure 11

```{r, fig.height=7.2, fig.width=7.2, warning = F, message = F, echo = F, fig.cap = "**Supplemenary figure 8. Group level posterior predictive checks of the 3 types of responses, Confidence, binary (faster or slower) and reaction time on the binary response for the non-nested Hierarchical model.** Facets represent the 3 types of responses, 0-1 Confidence ratings, 0 or 1 binary responses of (faster or slower) and the reaction time for these binary responses. Red line depicts the mean of the posterior and the blue lines represents 100 posterior draws."}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Supplementary figures","Supplementary figure11.PNG")), scale = 1)

```

\newpage

## Supplementary tables

### Supplementary table 1

see [Supplementary table 1](https://github.com/JesperFischer/Master-thesis/blob/main/Supplementary%20tables/Supplementary%20table2.xlsx) which is linked to the github of the thesis. As the table is to big to show on a single page.


### Supplementary table 2

<!-- this is table of the posterior estimates of the ICC binary model -->

```{r, fig.height=7.2, fig.width=7.2, warning = F, message = F, echo = F}

table_sup2 = read.csv(here::here("Supplementary tables","Supplementary table2.csv")) %>% mutate(X = NULL)


table_sup2 = flextable::flextable(table_sup2) %>% width(c(1), width = 1.5)



table_sup2 = set_caption(table_sup2,
  caption ="Table supplementary 2: Group mean parameter distributions of Binary test re-test re-analysis. Summary statistics of the group mean parameters of the Binary hierarchical model, used as the baseline parameters for the power analysis.")

table_sup2

```

\newpage

## Supplementary Notes:

### Supplementary note 1: Priors

In the section for Standard parameter recovery a single fit psychometric function was used to demonstrate the standard parameter recovery approach to internal validity of the psychometric function. The priors for that model were as follows for the threshold,slope and lapse rate respectively.

$\alpha \sim N(0,20)$
$\beta \sim N(0,2)$
$\lambda \sim N(-4,2)$

Next the priors for the nested hierarchical model was as follows:

$\mu_{\alpha} \sim N(0,10)$
$\sigma_{\alpha(within)} \sim N(0,10)$
$\sigma_{\alpha(between)} \sim N(0,10)$

$\mu_{\beta} \sim N(0,3)$
$\sigma_{\beta(within)} \sim N(0,3)$
$\sigma_{\beta(between)} \sim N(0,3)$


$\mu_{\lambda} \sim N(-4,2)$
$\sigma_{\lambda(within)} \sim N(0,3)$
$\sigma_{\lambda(between)} \sim N(0,3)$

$\rho_{between} \sim LKJ(2)$
$\rho_{within} \sim LKJ(2)$


### Supplementary note 2: Lapse rate explanation

As mentioned in the main text, the lapse rate can be quite difficult to estimate if the proportion of lapses are low. In the main text it is argued that lapse rate of approximately 1% is difficult to estimate as this would on average in the particular simulation with 100 trials per subject amount to 1 trial where the subject would have a lapse. However from the models perspective, these lapses are not created equally, which makes it even more dificult to estimate this parameter. This is because of the difference between having a lapse when the stimulus value is extreme in either end (high or low) or having a lapse when the stimulus value is close to the simulated threshold. A lapse close to the simulated threshold would from the models perspective not interfere with the estimation of the parameters as this response could just be due to the stochastic nature of the task (i.e. the y-axis of the Psychometric function is the probability of responding 1). Therefore only lapses at the extreme ends would inform the model about the underlying probability of having a lapse.



### Supplementary note 3: Pathfinder explanation

The pathfinder algorithm was used for optimization of the trial by trial simulations. The implementation was as follows. Firstly a randomly drawn stimulus value in the domamin of [-50 ; 50] was drawn. After the representation of this stimulus value a response is collected based on the simulated parameters. The stimulus value together with the responses is then fit to pathfinder which uses the priors of the model with this observation to update the parameters. The next stimulus is then selected by taking the posterior mean of the threshold. This was done for the first 5 trials to get resonable estimates of the parameters of the model. In order to properly explore the width and size of the psychometric function the stimulus values were after the first 5 trials selected based on a single draw from the posterior threshold and slope. This meant extracting a draw of the threshold and then randomly either adding the draw of the slope or subtracting it. For the  [full code see](https://github.com/JesperFischer/Master-thesis/blob/main/Analyses/ICC%20analysis/Visualizing%20pathfinder%20scripts.R). The priors for this model are identical to those found in the single subject psychometric function (see supplementary note 1)


### Supplementary note 4: Comparison of ADO algorithms

Comparison between the 3 tested model rested on having each algorithm simulate stimulus values based on simulated parameter values. These simulated stimulus values were then used to obtain responses of the agents (again using the simulated parameter values). Each set of stimuli and responses for each algorithm were then fit using the same Bayesian model (see supplementary note 3 and 1) and the posterior distributions were computed for each of the three parameters values (i.e. threshold $\alpha$, slope $\beta$ and lapse rate $\lambda$).

### Supplementary note 5: Posterior preditive checks

Supplementary figure 8 and 10 displays the posterior predictive check for the two hierarchical models with the three types of responses i.e. binary, reaction time and confidence ratings. In these plots the group means of the parameters are depicted giving an indicating of the overall structure of the behavioral responses of the participants. 

Supplementary figure 9 and 11 depicts instead of the group level estimates a particular participant at a particular session with overlaid data. Interrested readers are refered to [the github ](https://github.com/JesperFischer/Master-thesis/blob/main/manuscript/Supplementary%20material/supplementary%20analyses.Rmd) to explore other participants than depicted here.

Note that for the non-nested hierarchical model the group level estimates are the mean of the two sessions whereas this is directly estimated in the nested hierarchical model.


### Supplementary note 6: Power analysis model description

The full stancode for the model used in the power analysis, see [the github](https://github.com/JesperFischer/Master-thesis/blob/main/Analyses/Power%20analysis/Make%20datasets/Parameterized%20cummulative%20normal.stan). The model assumes that all three parameters of the psychometric function is drawn from a multivariate normal distribution with group means and between subjects variances, furthermore two group differences are also drawn from this multivariate normal distribution that calculates the the difference between slopes and thresholds between sessions. The variance co-variance matrix was decomposed using the Cholesky-decomposition and the LKJ-prior was used for the correlation coefficients between parameters which was set to $\eta = 2$ i.e. a quite wide prior on the correlation but with less mass for more extreme correlations.
