# Uncertainty minimization

## *Adaptive design optimization*

An import consideration of the parameter recovery described above, is what the design of the experiment that the agent goes through. Looking back at figure 6 providing stimulus values in the far ends of the psychometric functions i.e. in the ranges of [-50 ; -25] and [25 ; 50] will in most cases, for most agents, give next to no information on the shape of the psychometric and therefore the parameters we mostly care about i.e. the threshold and slope, see supplementary note 2 for the lapse rate. On average the agents’ psychometric functions are monotonically increasing in the interval of [-25 ; 25]. Therefore, selecting stimuli (inputs) in this interval must be better for decreasing the estimation uncertainty in the two parameters that are most often interpreted, compared to randomly or uniformly exploring the input space. one might even go a step further and instead of selecting inputs that are more appropriate for the mean of the population, one could individualize each experiment to the participant. This practice of individualizing the experiment of interest is called adaptive design optimization (ADO) and revolves around selecting inputs that are optimal given a specific criterion [@watson_quest_2017; @prins_psi-marginal_2013]. Many of these criterion exists such as minimizing entropy, minimizing the posterior variance or mutual information, but what they all have in common is that they decrease estimation uncertainty of either all or certain parameters to a meaningful degree. One of the main challenges of utilizing ADO is that because the experiment is updated and individualized on a trial by trial basis the algorithm determining the stimuli must run in tandem with the experiment. This puts high constraints on computation time of the algorithm. This particular issue has partly been solved in the existing packages by calculating a grid of a particular resolution of parameter values at at a trial and then using the optimization stategy to find the next optimal stimulus value. This clever solution puts the heavy computation time before the experiment and ensures that when the experiment is run only a single look up is needed to provide the next stimulus value on each trial. This approach works great for psychophysical experiments or other experiments where each trial is independent of the next. This is because only a single optimization step is required for each trial, whereas if trials were mutually dependent as in a learning experiment, then the algorithm would need to calculate all possible lines of stimuli and responses until a certain point which given the combinatorics can become a daunting task.

In order to keep coherence with the rest of the thesis, I will demonstrate how leveraging the single-fit model designed for conducting the single-subject parameter recovery can used together with the understanding of informative stimulus values described above to make a custom ADO algorithm. The advantages of being able to write such a custom algorithm is two-fold. Firstly, as long as the model can be written to invert observed data to parameter values (i.e. fit a model to data), then it can also be used to simulate stimulus values, this therefore increases the flexibility in model selection. Secondly, as this approach is not optimial for stimulus selection the method can even be extended to mutually dependent experiments. Illustrating this approach can be done by using variational inference algorithms that can quickly estimate an approximate posterior distribution of the parameters of interest, in this particular thesis the pathfinder algorithms implemented in Rstan is used [@zhang_pathfinder_2022]. The rationale behind this approach to ADO is to iteratively fit the model as responses from the participant is collected, the parameter estimates of the model is then updated and a new stimulus value is then selected based on these estimates and the knowledge of which stimulus values are the most informative for particular parameter values. For a full description of how the pathfinder algorithm was implemented, see supplementary note 3.

Figure 10 shows how the posterior distribution of the 3 parameters of the PF varies as a function of trials in both the previously used uniform selection of stimulus values and the implemented pathfinder approach. As can be seen both approaches makes the parameters converge towards the real simulated values (black line), however the speed at which this happens is different, especially for the two parameters that the pathfinder algorithm is optimizing for i.e. $\alpha$ and $\beta$. For these two parameters after just 20 trials using the pathfinder optimization has found the simulated parameter value and decreased the estimation uncertainty (95% credbility interval), whereas even after 50 trials the uniform approach still has a bit of a bias in the estimation, the individual points are not on the black line, but also a substantial estimation uncertainty associated with it. For completeness a PSI-algorithm was also used, in order to compare the feasibility of this new approach due to the high constraint on computation time of the algorithm [@kontsevich_bayesian_1999]. Interestingly the pathfinder algorithm ran in 14 seconds for the 50 trials whereas the PSI algorithm ran in 30 seconds. This highlights the feasibility of this approach as experimental designs have to be able to run relatively quickly, in order to keep the attention of the subject [@kwon_adaptive_2023].

<!-- pathfinder vs psi vs uniform plot -->
```{r figure 10, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "**Figure 10 comparison of algorithms to obtain stimulus values of the psychometric function** "}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","Pathfinder.PNG")), scale = 1)
```

To more formally show the differences in these ways of selecting stimulus values across a range of trial numbers, the Pathfinder, Uniform and PSI algorithms were run 100 times for trials ranging from 20 to 100 in a sequence of 10 trials (using the same range of parameter values as depicted in table 1). In order to make the comparison as fair as possible each of the algorithms were only used to generate the stimulus sequence, meaning that all data-sets were refitted using the same single fit Bayesian model for the final estimate that was compared to the simulated value, the same model used for conducting the single subject parameter recovery. For complete details on the fitting and optimization strategy see supplementary material note 3 and 4, as well as prior initialization for PSI and Pathfinder. Figure 11 shows the results of this simulation with the top panel showing the bias, i.e. the difference between the estimated and simulated parameter values and the bottom panel the uncertainty in the estimated parameter value. Interestingly, overall the PSI-ADO performs the worst both in terms of bias in the slope (Beta) and lapse rate (Lambda) parameter but especially in the estimation uncertainty for all parameters. The main difference between the uniform and Pathfinder approach seem to be in the estimation uncertainty and especially in the threshold (alpha).


<!-- pathfinder vs psi vs uniform plot over many iterations-->
```{r figure 11, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "**Figure 11.** shows how the estimation uncertainty and bias changes according to the number of trials and parameter value estimated with the different methods. "}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","Pathfinder_bias_estimation.PNG")), scale = 1)


```


Having tested and compared the pathfinder algorithm, it is now possible to examine three other focal points of minimizing estimation uncertainty in the parameter values, i.e. subjects, trials and the influence on the mean simulated slope value. The last point is less obvious than the two others but stems from the fact that increasing the slope (decreasing the steepness) of the PF will make it harder to estimate all the parameters of the function i.e. the estimation uncertainty is increased if other factors are held constant, the reason for this will become clear below. The number of subjects might also influence estimation uncertainty as the partial pooling effect of the hierarchical model will be stronger with more subjects.  For this purpose of investigating these three focal points, trials ranging from 20 to 200 in increments of 20, subjects being between 10, 30 and 50 and lastly mean slope values of 1,2 and 3 in the unconstrained space are simulated, with all other parameter values being identical to table 1. To guard against simulations that are not representative due to either bad convergences in the ADO or in the fitting procedure, each combination was run 5 times. Figure 12 displays the result of this parameter recovery across trials and group mean slope levels  (i.e. simulated beta values). Figure 12 only displays the correlation approach with inclusion of estimation uncertainty in the upper panel and the developed $ICC_2$ in the lower panel, for the two other metrics i.e. the correlation approach without estimation uncertainty and the $ICC_1$ see supplementary figure 3. Due to the limited influence of subjects these have been aggregated, Supplementary figure 4 and 5 displays the individual subject simulations separately.
 
```{r figure 12, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "**Figure 12 comparison of parameter recovery metrics.** First row depicts how the estimate of the correlation coefficent between simulated and estimated means change as a function of trials (x-axis) and the simulated mean slope (color) for each parameter of the psychometric function (columns). The bottom row shows how the estimate of $ICC_2$ changes based on the same metrics as the correlation coefficient. Note that the correlation coeffecient has been uncertainty propergated using bootstrapping."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","ICC_vs_correlation.PNG")), scale = 1)
```

From Figure 12, the main differences between the two approaches is that the ICC metric is generally lower than the correlation approach, but both asymptotically move towards one with increasing trials and or simulated mean slopes of the psychometric function. One way to highlight the difference and the meaning of these difference is to plot the pairwise scatter plot of simulated vs recovered parameter estimates. These pairwise scatter plots are what both metrics in Figure 12 attempt to describe. Picking the instances where the difference between the correlation and ICC approach is the greatest will give insight to which metric might be more suitable. Figure 13 therefore shows the pairwise scatter plot of the threshold in three selected trials (40, 120 and 200) for both steep and shallow slopes (means of 1 and 3 respectively for beta). These instances were chosen because the estimate of the correlation and ICC were similar for the steep slopes but remarkably different with shallower slopes of the psychometric function. Figure 13 clearly shows why there is such a difference between the two approaches, the ICC metric is penalized much more by the increased estimation uncertainty in the threshold of shallower slopes than the correlation coefficient together with the deviation from the identity line. These observation indicates that the ICC metric is much more sensitive to the uncertainty of which it is calculated compared to the correlation approach. The same reasons apply for the difference in the slope estimate itself and pairwise scatter plots can be found in supplementary figure 6. Lastly both approaches suggest that the lapse rate is below the two other metrics without much improvement with increasing trials, but still with the ICC being more conservative. 

```{r figure 13, fig.width = 7.2, fig.height = 5, warning = F, message = F, echo = F, fig.cap = "**Figure 13.** Showing the pairwise scatter plots of simulated vs recovered threshold ($\\alpha$) parameter when the simulated beta value is low (beta = 1) and high (beta = 3) for subjects (rows) and trials (columns)."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","scatter_plot.PNG")), scale = 1)
```


As conveyed by the pairwise scatter plots in figure 13, the conservative ICC metric capture the fact that estimation uncertainty is a source of variability that can still be reduced even when the correlation coefficient might indicate close to perfect fit. This is exactly the behavior one would like to have when trying to understand their model as this information is much more sensitive. Furthermore the values also have a natural interpretation in the case of ICC whereas for the correlation coefficient the interpretation is not straightforward. An ICC value of 0.8 means that 80% of the variance in the model is governed by the between subject level variance and only 20 % is in the estimation or test -retest uncertainty. The ICC could of cause be further decomposed into what proportion of variance of the 20% is from estimation and what is from test retest uncertainty, again see supplementary figure 3. This straightforward interpretation is not present for the correlation coefficient, especially because of the arguments laid forth in the “Current problems with internal recoverability of models (parameter recovery)” section. 

Another import considerations that has been deployed here which is sometimes neglected in parameter recovery analyses in the literature is the hierarchical structure, as mentioned in the previous section [@hess_bayesian_2024; @hubner_improving_2020 @harrison_interoception_2021]. Lastly what this approach also highlights is that parameter values in a cognitive model does not necessarily have to improve with increasing trials. This is the case for the lapse rate (lambda parameter) in this particular PF and could perhaps have been improved if the ADO algorithm was tuned to estimate this parameter. Therefore mindlessly increasing the number of trials to hopefully decrease estimation uncertainty on a parameter should be done after having conducted such an analysis in order to ensure that resources are not wasted trying to decrease estimation uncertainty, when its not possible. 


## **Increasing information in cognitive models**


The previous section highlighted how the number of trials and the group level slope, but not the number of subjects could influence the parameter recovery metric i.e. correlation coefficient or $ICC_2$. In this section it will described how using data and or information about the underlying experiment or generative model, estimation uncertainty can be further reduced (and thereby increase the parameter recovery metric) in the parameter estimates of interest. For the sake of this thesis, I will look at incorporating the reaction times of the agents’ responses as sources of information about the underlying PF of their binary choices. I will be focusing on the reaction times as these have a long and rigorous history in the  cognitive science literature, but more importantly are present in many experiments conducted today [@sternberg_memory-scanning_1969; @pirolli_role_1985; @macleod_training_1988]. In order to incorporate the reactions times into the current formulation of the generative structure of the task, it is helpful to think of the output of PF as a probability of responding a particular value, say 1. This therefore entails that in either end of the tail of the PF the certainty with which you respond is the highest and the midpoint between the extremes (the threshold) is the most uncertain. This descriptive formulation is what the variance of the Bernoulli distribution describes, which is the distribution used to convert probabilities to binary choices:

$$
Var(Bern(p)) = p \cdot (1-p)
$$
Using this information together with the assumption that participants will respond slower when more uncertain and faster when certain, the reactions times of each trial can be modeled as a linear combination of this Bernoulli variance. This linear combination would entail an intercept to account for the individual differences in mean reaction time and a slope that scales the influences of the uncertainty to the variances of the underlying PF i.e. the Bernoulli variance. Mathematically this would entail:
$$
RT \sim intercept + \beta_{RT} * Var(Bern(p))
$$
where intercept represents the intercept and $\beta_{RT}$ represents the degree to which the uncertainty from the psychometric function influences the reaction times, see Figure 14 for a visualization of this mapping. In order to stochastically model the reaction times with this formulation a probability density function is needed to account for the noise observed. Due to the non negative nature of reactions times and the physical constraints of information processing (i.e. a delay from the time the stimulus is presented to which it reaches the brain of the agent), a sensible choice of this probability density function would be the shifted log normal distribution. This introduces two more variables, a non decision time ($\tau$) and a standard deviation ($\sigma$) for the log normal distribution [@ranger_modeling_2020; @jain_comparative_2015]. This formulation of the reactions times therefore follow the relationship described below, where the crucial link, linking the psychometric function and the reaction times being the Bernoulli variance.

$$
RT \sim LogNormal(intercept + \beta_{RT} * Var(Bern(p), \sigma) + \tau
$$

To show how these reaction times help with recovery of the parameters of interest i.e. the threshold and slope of the PF, agents with the parameter values displayed in table 2 were simulated. To understand the influence of the size of coupling between the binary responses and the reaction times ($\beta_{RT}$) this parameter was simulated with either a high or low group mean, 1.5 and 1 respectively. The steepness of the slope of the PF was also varied between high and low, 1 and 3 respectively. Again, showing and understanding what these parameter values mean, one simulates the parameters and display the behavior. This can be seen in figure 14 where 10 simulated subjects are visualized. The figure clearly shows the relationship between the PF and the reaction time function. In the high stimulus values i.e. the most extreme x-values the reaction times are fast and the psychometric function is approaching 0 or 1. As the PF increases from very low stimulus values (the left side), the reactions times increase up untill the threshold for that agent is reached and then decreases. 


```{r Table 2, warning = F, message = F, echo = F}
table2 = read.csv(here::here("tables","table2.csv")) %>% mutate(X = NULL)

table2 = flextable::flextable(table2) %>% flextable::width(c(1), width = 1.3) %>% 
  flextable::width(c(4), width = 1.8) %>% 
  flextable::width(c(2:3), width = 1.2) 


table2 = set_caption(table2,
  caption ="Table 2: Parameter distributions for reaction time simulations. Parameter distributions for the simulated agents and the transformations for each of the parameters when including the Reaction times in the psychometric function.")

table2
```

```{r figure 14, fig.width = 7.2, fig.height = 5, warning = F, message = F, echo = F, fig.cap = "**Figure 14. Visualization of the psychometric function with Reaction times.** Upper panel depicts 10 psychometric functions where parameters were drawn from table2 (Beta = 3 and BetaRT = 1.5). Lower Panel depicts the assumed relationship between the stimulus value (x) and the reaction times (y), which as can be seen is dependent on the shape of the psychometric function in the upper panel. The reaction time functions peak around the psychometric threshold and tapers off when the psychometric function asympotes at 1 or 0."}
cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","plot13_psychometric_RT.png")), scale = 1)
```

Next utilizing this generative model a parameter recovery analysis can be conducted that investigates the influence of these reactions times on the recovery of the parameters of the PF. Here only the $ICC_2$ are depicted for the 8 combinations of slope, size of the coupling and inclusion of reaction time is depicted. Similar results were obtained by using the correlation coefficient, which can be seen in supplementary figure 7.

Figure 15 displays the difference in parameter recovery between including reaction times in the modeling or not, on the 3 parameters of the psychometric function. The plot firstly highlights increased $ICC_2$ values for the two parameters of particular interest i.e. the threshold (Alpha) and the slope (Beta). This difference seems to be present in the slope for both slope conditions (i.e. steep and shallow simulated mean slopes i.e. 1 and 3) but also in the shallow simulated slope (beta = 3) for the threshold where the $ICC_2$ metric has not reached its asymptote of 1 as in the steep slope simulation.

```{r Figure 15, fig.width = 7.2, fig.height = 7.2, warning = F, message = F, echo = F, fig.cap = "Figure 15 Parameter recovery of the psychometric function for the ICC for each parameter (columns), in each combination of including and not including rts and its size (color), and the simulated mean slope (rows) for differing number of trials x-axis. Stronger coupling is associated with better parameter recovery effects for both threshold slope, and lapse rate, with a strength dependent association i.e. the higher the coupling strength the more improve recovery when comparing to not uterlizing reaction times."}

cowplot::ggdraw() +
    cowplot::draw_image(magick::image_read(here::here("Figures","ICC_rtplot.PNG")), scale = 1)
```
