## *Real data!*

Having rigorously investigated how the psychometric function behaves and how the certainty of the parameters interacts with each other but also with the number of trials for each subject, one can now turn to real data. I’ll in this section introduce the published dataset that I will re-analysis utilizing the psychometric functions introduced above. The goal with this re-analysis is 2-fold. Firstly, it reiterates the fact that the assumptions about the structure of the data can make quite a difference in the parameter estimates and their uncertainty. Secondly, it will serve as a starting point to understand why the internal model validity using the ICC can be helpful as a metric to gauge how trials and subjects interact on the statistical power of a model to reject a hypothesis. This last aspect of testing hypotheses will tie together how these validity steps help determine the ability of a model to do what researchers are many times interested in i.e. hypothesis testing. The last point of the thesis is going revolve around conducting a thorough power analysis of the current model, utilizing the published dataset described below here I will compare the ICC metric for the model to its ability to reject hypotheses at certain trial and subject numbers. In this regard of conducting a power analysis I will again highlight where uncertainty creeps in and how we can deal with and account for these, as common practices are insufficient.


## *Heart rate discrimination task* 

The article where the dataset was published is @legrand_heart_2022 and is an interoceptive task. Here the authors collected 223 participants who came in twice to complete a heart rate discrimination (HRD) task within 6 weeks between visits.  The HRD task is comprised of two distinct tasks, a comparison and an interoceptive task. Here I’ll focus on the Interceptive task where participants were asked to internalize their own heart rate for 5 seconds. Meanwhile the participant attends to their own heart rate, the heart rate is monitored and calculated in real time. Next based on the observed heart rate participants will hear five auditory tones in a frequency (not the internal frequency of the tone, but the frequency of how fast the tones is presented) that is either faster or slower than their own objective heart rate. The amount this auditory tone frequency was faster or slower was determined by the PSI procedure introduced in the Adaptive design optimizing paragraph. This means that the stimulus value for the psychometric function is the difference between the external tones frequency and the observed heart rate of the participant in the current trial and the responses are given by faster or slower with faster being coded as 1 and slower being coded as 0. This means that a participant might have a heart rate of 50beats per minute (BPM) at a particular trial and then hear tones in a frequency of 40 BPM and are asked to respond whether they think this 40BPM is slower or faster than their own heart rate. The authors of the experiment, described above, ended up running single participant level models of each subject, for each session, and then correlating the slope and threshold of the psychometric function. They found a medium correlation between the threshold r = 0.51 p < .001 between sessions and a negligible correlation r = 0.1, p = .15 for the slope. In the next section I will show how this reliability might change given different model assumptions and different models, to demonstrate that thinking hard about what model is fitted is worthwhile.

## *The models*

In this section I will describe the models that I’ll fit to this big test-retest dataset to examine the influence of the model fit on the correlation between session one and two.
The single fit model is going to be the references and going to be the same as the original authors did. That is estimating each individual for each of the sessions individually without a lapse rate (i.e. a two parameter psychometric function) and then post hoc correlating the estimates between session one and two. I will add the propagated uncertainty to these estimates as they do not seem to be adjusted by the authors. Next, I’ll investigate the same model as above but adding the third lapse parameter. The hierarchical model is going to model the two sessions from the same multivariate normal distribution. This model directly models the correlation between sessions as its included in the variance - covariance matrix of the multivariate normal distribution. The last type of model is the nested hierarchical model, this model assumes that all subjects have a mean level parameter which is drawn from the same multivariate distribution, then each parameter for each session is then drawn from a subject level distribution, identical to the model presented in the ICC parameter recovery section. For this last model the ICC is the statistical metric estimated by the model itself, and the correlation will afterwards be calculated. Additionally, each of these models will be fitted using the reaction times as described in the XXXX section to investigate the influence of adding this additional information. A final full model is going to be fit utilizing even more information already available in the dataset. This model will not only incorporate the reaction times on a trial-by-trial basis, but also the confidence ratings for each trial. These confidence ratings were included in the task of the original experiment to examine the participants’ interoceptive metacognitive abilities.  These confidence ratings are going to be modelled in close resemblance to the reaction times, just inverted. This inversion is because in the middle of the psychometric function the uncertainty about the stimulus representation is the highest and therefore reaction times should be their highest as well, but confidence should be at the lowest. Another difference between the reaction times and the confidence ratings is their range of possible values. Confidence ratings were bounded between 0 and 100 indicating complete uncertainty and certainty respectively. A natural likelihood function for such kind of double bounded variables is the beta distribution as its already bounded between 0 and 1. The only problem with using this likelihood function is the edge cases of 0 and 1’s which for the confidence ratings are 0 and 100. One approach is to model these edge values separately using a zero-one-inflated beta distribution. This approach, however, models these edge values as separate processes which does not make sense in this case as the confidence ratings are meant to represent a continuous measure of confidence. I will therefore here subtract 0.1 from the 100 ratings and add 0.1 to the 0 ratings making it possible to use the beta distribution for the full range of confidence ratings. This approach of modeling the bounded ratings between 0 and 100 is tenuous and new mixture methods are slowly being developed for a more holistic approach see @kubinec_ordered_2023. Reaction times of the responses were at maximum 8 seconds and can therefore still be modeled by the shifted lognormal distribution introduced above. 

## *Results*

Table 3 displays the correlation coefficient between the first and second session for the threshold and slope for each model when uncertainty has been propagated using bootstrapping. For a full table of all parameters of all models as well as with and without uncertainty propagation see supplementary table XYX



```{r table3, fig.width = 7, fig.height = 7, warning = F, message = F, echo = F, fig.cap = "**Table 3. Results from reanalysis of legrand (2022).** Table showing the correlation between sessions of the threshold and slope parameter of the psychometric function using different model fomulations as well as hierarchical model structures."}
table3 = read.csv(here::here("tables","table3.csv")) %>% mutate(X = NULL)


table3 = flextable::flextable(table3) %>% width(c(1,2), width = 1.8)%>% width(5, width = 1.1)%>% width(4, width = 1.4)

table3
```



Table 3 clearly highlights the fact that the additional assumptions of the hierarchical models both nested and unnested increases the session-by-session correlation of the slope of the psychometric function, and that additionally including the reactions time increase the correlation even more. The main difference in session-by-session correlation between the two hierarchical models can be found in the threshold as the nested hierarchical model outperforms the non-nested hierarchical model in this regard. A concern of this approach of just looking the correlation coefficients is of cause that a model with a high session by session correlation might not fit the data the best, as the latent underlying stability i.e. correlation might be 0. One approach would therefore be to examine model fit using common metrics such as cross validation, information criterion etc. This difficulty here is that most of the models are incompatible; because they have been fit to differing amounts of subjects in the case of hierarchical vs single fit models, and to differing amounts of dependent variables in the case of within model architecture. The only models being compatible for comparison are the two hierarchical fit models with the same model architecture, resulting in a very limited comparison.


