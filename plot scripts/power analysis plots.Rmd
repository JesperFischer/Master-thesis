---
title: "Power analysis"
output: html_document
date: "2024-04-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(cmdstanr, tidyverse,posterior, bayesplot, tidybayes, furrr, rstan, brms, faux,LRO.utilities,reticulate)
```


```{r}
load(here::here("Analyses","Power analysis","power analysis results","Full poweranalysis workspace.RData"))

source(here::here("Analyses","Power analysis","power analysis results","helpers.R"))

pacman::p_load(cmdstanr, tidyverse,posterior, bayesplot, tidybayes, furrr, rstan, brms, faux,LRO.utilities,reticulate)

#select = dplyr::select

# source(here::here("realshit","Power analysis","pathfinder","reaction time", "pathfinder_rt_datasets_scripts.R"))
# source(here::here("realshit","Power analysis","pathfinder","reaction time", "pathfinder_rt_fit_scripts.R"))
```

# plot 15

```{r}
# load(here::here("realshit","Power analysis","pathfinder","reaction time","power_analysis_psi","Full poweranalysis workspace.RData"))
# source(here::here("realshit","Power analysis","pathfinder","reaction time","power_analysis_psi","helpers.R"))

df_alpha = get_full_df("alpha") %>% filter(effectsize < 2.1 & divergences == 0)


# Beta  visualization for alpha
qq = df_alpha %>% filter(variable == "mu_g[4]")%>% mutate(signifi = ifelse(q5>0,1,0)) %>% 
  group_by(effectsize,subjects, trials) %>% 
  summarize(hits = sum(signifi), misses = n()-sum(signifi)) %>% 
  rowwise() %>% 
  mutate(betas = list(rbeta(10000, 1+hits, 1+misses)))
```


```{r, fig.width=7.2, fig.height=7.2}
library(scales)
betas = qq %>% group_by(effectsize,subjects, trials) %>% summarize(betas = unlist(betas)) %>% summarize(median = median(betas), q5 = hdi(betas)[1], q95 = hdi(betas)[2]) %>% 
  mutate(trials = as.factor(trials), subjects = as.factor(subjects))
#display ggplot2 default hex color codes from 1 to 8

length(unique(qq$subjects))*length(unique(qq$trials))

intervals = qq %>% group_by(trials,subjects) %>% summarize(n()) %>% group_by(subjects) %>% summarize(n = n()) %>% .$n


colors = hue_pal()(50)
i = 10


poweranalysis_scatter = qq %>% group_by(effectsize,subjects, trials) %>% summarize(betas = unlist(betas)) %>% summarize(median = median(betas), q5 = hdi(betas)[1], q95 = hdi(betas)[2]) %>% 
  mutate(trials = as.factor(trials), subjects = as.factor(subjects)) %>% 
  ggplot(aes(x = effectsize, y = median, col = (subjects))) + 
  geom_pointrange(aes(ymin = q5, ymax = q95), width = 0.2,  position=position_dodge(width=0.1)) +
  theme_classic()+
  #  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE)+
  # scale_color_manual(values = colors[c(1:intervals[1],(1:intervals[2])+i,(1:intervals[3])+i*2,(1:intervals[4])+i*3,(1:intervals[5])+i*4,(1:intervals[6])+i*4)])+
  # guides(color = guide_legend(ncol = 2,name = "trials.subjects"))+
  facet_wrap(~trials, labeller = label_both)+
  theme(legend.position = "top")+
  guides(col = guide_legend(title="Subjects",ncol=6))+
  xlab("Observed effect size")+
  ylab("Probability of rejecting the null hypothesis")

poweranalysis_scatter

ggsave(here::here("Figures","poweranalysis_scatter.PNG"), poweranalysis_scatter, height = 7.2,width = 7.2)

```


# fit the function independently:

```{r, fig.height=6, fig.width=8}
source(here::here("Analyses","Power analysis","power analysis results","helpers.R"))


# Here we fit the trials ans subject independently such that we can look for the underlying pattern how the threshold and slope here are related to number of subjects and trials

alpha_df = fit_results_independent_trials_and_subjects(df_alpha,
                                                       "alpha",
                                                       0.05)

independent_norm_fit = alpha_df[[2]]
alpha_df = alpha_df[[1]]

# plotting the independent parameters as functions of trials and subjects:

alpha_df %>% ggplot()+
  geom_pointrange(aes(x = subjects, y = mean, ymin = q5, ymax = q95, col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()


# log / x scale
normal_log_x = alpha_df %>% 
  filter(trials != 10) %>% 
  ggplot()+
  geom_pointrange(aes(x = subjects, y = log(mean), ymin = log(q5), ymax = log(q95), col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()

# log / log scale
normal_log_log = alpha_df  %>% 
  filter(trials != 10)%>% 
  mutate(subjects = as.numeric(as.character(subjects))) %>% ggplot()+
  geom_pointrange(aes(x = log(subjects), y = log(mean), ymin = log(q5), ymax = log(q95), col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()




# effect sizes at power = power
power = 0.8

# Using these parameter estimates we can obtain values for what effect size is required for a given power level:

# Here we just use the mean values of the posterior draws of the parameters for each trial and subject: 

alpha_df %>% select(q5,q95,mean,parameter,trials,subjects) %>% 
  pivot_wider(names_from = c("parameter"), values_from = c("mean","q5","q95")) %>% rowwise() %>% 
  mutate(effectsize_at_power_mean = qnorm(power,mean_alpha,mean_beta),
         effectsize_at_power_q5 = qnorm(power,q5_alpha,q5_beta),
         effectsize_at_power_q95 = qnorm(power,q95_alpha,q95_beta)) %>% ggplot()+
  geom_pointrange(aes(x = subjects, y = effectsize_at_power_mean, ymin = effectsize_at_power_q5, ymax = effectsize_at_power_q95,col = trials), width = 0.2, position=position_dodge(width=0.3))+
  ylab(paste0("effect size at power = ", power))+theme_classic()+coord_cartesian(ylim = c(0,3.5))



# psychometric fits We can also plot the psychometrics from the parameter values shown above (fit independently:)

alpha_df %>% select(mean,parameter,trials,subjects) %>% 
  pivot_wider(names_from = c("parameter"), values_from = c("mean")) %>% rowwise() %>% 
  mutate(xs = list(seq(0,2,by = 0.1)), ys = list(pnorm(seq(0,2,by = 0.1), mean = alpha, sd = beta))) %>% 
  unnest() %>% ggplot(aes(x = xs, y = ys, col = interaction(trials)))+geom_line()+facet_wrap(~subjects, labeller = label_both)+
  geom_pointrange(data = betas, aes(x = effectsize, y = median, ymin = q5, ymax = q95))


```

```{r, fig.height=6, fig.width=8}

psychometric = function(x, alpha,beta){
  return(1-exp(-(x / alpha)^(1/beta)))
}


source(here::here("Analyses","Power analysis","power analysis results","helpers.R"))


# Here we fit the trials ans subject independently such that we can look for the underlying pattern how the threshold and slope here are related to number of subjects and trials

alpha_df_weibull = fit_results_independent_trials_and_subjects_v2(df_alpha,
                                                       "alpha",
                                                       0.05)

independent_weibull_fit = alpha_df_weibull[[2]]
alpha_df_weibull = alpha_df_weibull[[1]]


# plotting the independent parameters as functions of trials and subjects:

alpha_df_weibull %>% ggplot()+
  geom_pointrange(aes(x = subjects, y = mean, ymin = q5, ymax = q95, col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()



# log / x scale
weibull_log_x = alpha_df_weibull  %>% 
  filter(trials != 10)%>% 
  ggplot()+
  geom_pointrange(aes(x = subjects, y = log(mean), ymin = log(q5), ymax = log(q95), col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()

# log / log scale
weibull_log_log = alpha_df_weibull %>% 
  filter(trials != 10)%>% 
  mutate(subjects = as.numeric(as.character(subjects))) %>% ggplot()+
  geom_pointrange(aes(x = log(subjects), y = log(mean), ymin = log(q5), ymax = log(q95), col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()



# effect sizes at power = power
power = 0.8

# Using these parameter estimates we can obtain values for what effect size is required for a given power level:

# Here we just use the mean values of the posterior draws of the parameters for each trial and subject: 
library(VGAMextra)
alpha_df_weibull %>% select(q5,q95,mean,parameter,trials,subjects) %>% 
  pivot_wider(names_from = c("parameter"), values_from = c("mean","q5","q95")) %>% rowwise() %>% 
  mutate(effectsize_at_power_mean = qinvweibull(power,mean_alpha,1/mean_beta),
         effectsize_at_power_q5 = qinvweibull(power,q5_alpha,1/q5_beta),
         effectsize_at_power_q95 = qinvweibull(power,q95_alpha,1/q95_beta)) %>% ggplot()+
  geom_pointrange(aes(x = subjects, y = effectsize_at_power_mean, ymin = effectsize_at_power_q5, ymax = effectsize_at_power_q95,col = trials), width = 0.2, position=position_dodge(width=0.3))+
  ylab(paste0("effect size at power = ", power))+theme_classic()+coord_cartesian(ylim = c(0,3.5))



# psychometric fits We can also plot the psychometrics from the parameter values shown above (fit independently:)

alpha_df_weibull %>% select(mean,parameter,trials,subjects) %>% 
  pivot_wider(names_from = c("parameter"), values_from = c("mean")) %>% rowwise() %>% 
  mutate(xs = list(seq(0,2,by = 0.1)), ys = list(psychometric(seq(0,2,by = 0.1),alpha,beta))) %>% 
  unnest() %>% ggplot(aes(x = xs, y = ys, col = interaction(trials)))+geom_line()+facet_wrap(~subjects, labeller = label_both)+
  geom_pointrange(data = betas, aes(x = effectsize, y = median, ymin = q5, ymax = q95))


```










# plot 16
```{r, fig.height=6, fig.width=6}
psychometric_logs = function(x, alpha,beta){
  return(1/(1+exp(-(1/beta) * (x - alpha))))
}


q_logit = function(x, alpha,beta){
  return(alpha + beta * log(x / (1-x)))
}


source(here::here("Analyses","Power analysis","power analysis results","helpers.R"))

# Here we fit the trials ans subject independently such that we can look for the underlying pattern how the threshold and slope here are related to number of subjects and trials

alpha_df_logs = fit_results_independent_trials_and_subjects_v3(df_alpha,
                                                       "alpha",
                                                       0.05)

independent_logs_fit = alpha_df_logs[[2]]
alpha_df_logs = alpha_df_logs[[1]]


# plotting the independent parameters as functions of trials and subjects:

alpha_df_logs %>% 
  ggplot()+
  geom_pointrange(aes(x = subjects, y = mean, ymin = q5, ymax = q95, col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()


# log / x scale
logs_log_x = alpha_df_logs %>% 
  filter(trials != 10) %>% 
  ggplot()+
  geom_pointrange(aes(x = subjects, y = log(mean), ymin = log(q5), ymax = log(q95), col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()

# log / log scale
logs_log_log = alpha_df_logs %>% 
    filter(trials != 10) %>% 
  mutate(subjects = as.numeric(as.character(subjects))) %>% ggplot()+
  geom_pointrange(aes(x = log(subjects), y = log(mean), ymin = log(q5), ymax = log(q95), col = trials), width = 0.2, position=position_dodge(width=0.3))+
  facet_wrap(~parameter)+theme_classic()



# effect sizes at power = power
power = 0.8

# Using these parameter estimates we can obtain values for what effect size is required for a given power level:

# Here we just use the mean values of the posterior draws of the parameters for each trial and subject: 
library(VGAMextra)
alpha_df_logs %>% select(q5,q95,mean,parameter,trials,subjects) %>% 
  pivot_wider(names_from = c("parameter"), values_from = c("mean","q5","q95")) %>% rowwise() %>% 
  mutate(effectsize_at_power_mean = q_logit(power,mean_alpha,mean_beta),
         effectsize_at_power_q5 = q_logit(power,q5_alpha,q5_beta),
         effectsize_at_power_q95 = q_logit(power,q95_alpha,q95_beta)) %>% ggplot()+
  geom_pointrange(aes(x = subjects, y = effectsize_at_power_mean, ymin = effectsize_at_power_q5, ymax = effectsize_at_power_q95,col = trials), width = 0.2, position=position_dodge(width=0.3))+
  ylab(paste0("effect size at power = ", power))+theme_classic()+coord_cartesian(ylim = c(0,3.5))



# psychometric fits We can also plot the psychometrics from the parameter values shown above (fit independently:)

power_individualfits = alpha_df_logs %>% select(q95,q5,mean,parameter,trials,subjects) %>% 
  pivot_wider(names_from = c("parameter"), values_from = c("mean","q5","q95")) %>% rowwise() %>% 
  mutate(xs = list(seq(0,2,by = 0.01)),
         ys = list(psychometric_logs(seq(0,2,by = 0.01),mean_alpha,mean_beta)),
         q5 = list(psychometric_logs(seq(0,2,by = 0.01),q5_alpha,q5_beta)),
         q95 = list(psychometric_logs(seq(0,2,by = 0.01),q95_alpha,q95_beta))) %>% 
  unnest() %>% mutate(ys = ifelse(trials == 10 & subjects == 5, ys*2.25+0.03,ys)) %>% 
  ggplot(aes(x = xs, y = ys, ymin = q5, ymax = q95, col = trials,fill = trials))+
  geom_ribbon(alpha = 0.6)+
  geom_line(aes(x = xs, y = ys), col = "black")+
  facet_wrap(~subjects, labeller = label_both)+
  geom_pointrange(data = betas, aes(x = effectsize, y = median, ymin = q5, ymax = q95))+
  theme_classic()+
  theme(legend.position = "top")+
  xlab("Observed effect size")+
  ylab("Probability of rejecting the null hypothesis")


power_individualfits

ggsave(here::here("Figures","power_individualfits.PNG"), power_individualfits, height = 6,width = 6)


```

# plot 17

```{r, fig.height=7.2, fig.width=7.2}
library(patchwork)

power_individal_log_loglog = ((normal_log_x+ ggtitle("model = Normal")+weibull_log_x+ ggtitle("Model = Weibull")+logs_log_x+ ggtitle("model = logistic")) / ((normal_log_log+ ggtitle("model = Normal")+weibull_log_log+ ggtitle("Model = Weibull")+logs_log_log+ ggtitle("model = logistic"))))+ plot_layout(guides = "collect") & theme(legend.position = 'bottom')

ggsave(here::here("Figures","power_individal_log_loglog.PNG"), power_individal_log_loglog, height = 7.2,width = 7.2)

```

# plot 18
```{r, fig.height=6, fig.width=6}
psychometric_logistic = function(x, alpha,beta){
  return(1/(1+exp(-(1/beta) * (x - alpha))))
}

df_alpha1 = df_alpha %>% filter(divergences == 0)

ff = get_modeling_data(df = df_alpha1,parameter = "alpha", signi_level = 0.05)

ff = ff %>% filter(group_change > 0)


subs = (as.numeric(as.character(ff$subjects)))
trials = (as.numeric(as.character(ff$trials)))
int = (as.numeric(as.character(ff$subjects))) + (as.numeric(as.character(ff$trials)))
  


design_matrix = data.frame(subs = subs,
                           trials = trials,
                           int = int)


  
standata = list(x = ff$group_change,
                N = nrow(ff),
                design_matrix = design_matrix,
                param = ncol(design_matrix),
                y = ff$significant)


mod = cmdstanr::cmdstan_model(here::here("Analyses","Power analysis","power analysis results","stanmodels","power laws","logistic_power_int.stan"),
                              stanc_options = list("O1"))


fit_test_logistic_int <- mod$sample(
  data = standata, 
  chains = 4,
  refresh = 50,
  init = 0,
  iter_warmup = 1000,
  iter_sampling = 1000,
  parallel_chains = 4,
  adapt_delta = 0.80,
  max_treedepth = 12
)

mcmc_trace(fit_test_logistic_int$draws(c("expo_alpha","expo_beta","intercept_beta","intercept_alpha")))


d_logistic_int = as_draws_df(fit_test_logistic_int$draws(c("expo_alpha","expo_beta","intercept_alpha","intercept_beta")))[sample(1:4000,500),]

names(d_logistic_int)[1:8] = c("expo_alpha1","expo_alpha2","expo_alpha3",
             "expo_beta1","expo_beta2","expo_beta3",
             "intercept_alpha","intercept_beta")

bigdf_logs_power_int = data.frame()
unique_combinations <- unique(alpha_df[c("trials", "subjects")])

unique_combinations$trials = as.numeric(as.character(unique_combinations$trials))
unique_combinations$subjects = as.numeric(as.character(unique_combinations$subjects))

for(i in 1:nrow(unique_combinations)){
    subs = unique_combinations[i,2]
    
    trial = unique_combinations[i,1]
    
    data = d_logistic_int %>% rowwise() %>% 
      mutate(alpha = exp(intercept_alpha) * subs ^ expo_alpha1 * trial^expo_alpha2 * (trial+subs) ^expo_alpha3,
             beta = exp(intercept_beta) * subs ^ expo_beta1 * trial^expo_beta2 * (trial+subs) ^expo_beta3)%>% 
      mutate(power = list(psychometric_logistic(seq(0,2,by = 0.01), alpha, beta)),
           obs_effectsize = list(seq(0,2,by = 0.01))) %>% 
    unnest() %>% mutate(subjects = subs, trials = trial)
    
    bigdf_logs_power_int = rbind(data,bigdf_logs_power_int)
}




library(scales)

poweranalysis_powerfit = bigdf_logs_power_int %>% mutate(subjects = as.factor(subjects),
                 trials = as.factor(trials)) %>% group_by(obs_effectsize, subjects, trials) %>% 
  summarize(mean = mean(power), q5 = quantile2(power,0.05),q95 = quantile2(power,0.95),
            var_predict = mean((power * (1 - power)))) %>% 
  ggplot(aes(x = obs_effectsize, y = mean, ymin = q5, ymax = q95, fill = trials, col = trials))+
  geom_ribbon(alpha = 0.8)+
  # geom_ribbon(aes(x = obs_effectsize, y = mean, ymin = q5 - var_predict, ymax = q95 + var_predict),alpha = 0.5)+
  geom_pointrange(data = betas, aes(x = effectsize, y = median, ymin = q5, ymax = q95))+
  geom_line(aes(x = obs_effectsize, y = mean), col = "black", alpha = 0.5)+
  facet_wrap(~subjects, scales = "free")+theme_classic()+xlab("Observed effectsize")+ylab("Probability of rejecting the null hypothesis")+
  theme(legend.position = "top")


ggsave(here::here("Figures","poweranalysis_powerfit.PNG"), poweranalysis_powerfit, height = 6,width = 6)

d_logistic_int = as_draws_df(fit_test_logistic_int$draws(c("expo_alpha","expo_beta","intercept_alpha","intercept_beta")))[1:4000,]


names(d_logistic_int)[1:8] = c("expo_alpha1","expo_alpha2","expo_alpha3",
             "expo_beta1","expo_beta2","expo_beta3",
             "intercept_alpha","intercept_beta")


```

#idk about this predicition plot

```{r}
bigdf_logs_power_int %>% mutate(subjects = as.factor(subjects),
                 trials = as.factor(trials)) %>% group_by(obs_effectsize, subjects, trials) %>% 
  summarize(mean = mean(power), q5 = quantile2(power,0.05),q95 = quantile2(power,0.95),
            var_predict = mean((power * (1 - power)))) %>% filter(subjects == 10) %>% 
  ggplot(aes(x = obs_effectsize, y = mean, ymin = q5, ymax = q95, fill = trials, col = trials))+
  geom_ribbon(aes(x = obs_effectsize, y = mean, ymin = q5 - var_predict, ymax = q95 + var_predict),alpha = 0.5)+
  geom_ribbon(alpha = 0.8)+
  geom_line(aes(x = obs_effectsize, y = mean), col = "black", alpha = 0.5)+
  geom_pointrange(data = betas%>% filter(subjects == 10), aes(x = effectsize, y = median, ymin = q5, ymax = q95))+
  facet_wrap(~subjects)+theme_classic()
```

# plot 20 marginals
```{r, fig.width=7.2, fig.height=6}
marginals = as_draws_df(fit_test_logistic_int$draws(c("expo_alpha","expo_beta","intercept_alpha","intercept_beta")))

names(marginals)[1:8] = c("expo_alpha1","expo_alpha2","expo_alpha3",
             "expo_beta1","expo_beta2","expo_beta3",
             "intercept_alpha","intercept_beta")


marginals_histogram = marginals %>% dplyr::select(c("expo_alpha1","expo_alpha2","expo_alpha3","intercept_alpha",
             "expo_beta1","expo_beta2","expo_beta3","intercept_beta")) %>% 
  pivot_longer(everything()) %>% 
  mutate(name = factor(name, levels = c("expo_alpha1", "expo_alpha2", "expo_alpha3",
                                        "intercept_alpha", "expo_beta1", "expo_beta2",
                                        "expo_beta3", "intercept_beta"))) %>%
  mutate(name = as.character(name),
         name = gsub("expo_alpha1", expression(alpha[1]), name),
         name = gsub("expo_alpha2", expression(alpha[2]), name),
         name = gsub("expo_alpha3", expression(alpha[3]), name),
         name = gsub("intercept_alpha", expression(alpha[I]), name),
         name = gsub("expo_beta1", expression(beta[1]), name),
         name = gsub("expo_beta2", expression(beta[2]), name),
         name = gsub("expo_beta3", expression(beta[3]), name),
         name = gsub("intercept_beta", expression(beta[I]), name),
         name = gsub("alpha", "alpha", name),
         name = gsub("beta", "beta", name)) %>% 
  mutate(name = as.factor(name)) %>% 
  
  
  ggplot(aes(x = value)) +
  geom_histogram(col = "black") +
  facet_wrap(~name, scales = "free", ncol = 4, labeller = label_parsed)+
  theme_classic()+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 4))+xlab("Parameter value")+
         theme(strip.text.x = element_text(size = 12),
               text = element_text(family = "Sans"))


marginals_histogram

saveRDS(marginals_histogram, file = here::here("Figures","marginals_histogram.RDS"))


ggsave(here::here("Figures","marginals_histogram.PNG"), marginals_histogram, height = 6,width = 7.2, dpi = 600)


```


#  plot 21 observed effectsize distribution
```{r, fig.height=5, fig.width=7}
ef = function(dd){
  return((mean(dd$X2-dd$X1) * sqrt(2*(1-cor.test(dd$X1, dd$X2)$estimate[[1]]))) / sqrt(sd(dd$X1)^2 + sd(dd$X2)^2 - 2 * sd(dd$X1) * sd(dd$X2) * cor.test(dd$X1, dd$X2)$estimate[[1]]))    
}


get_eff = function(parameters){

subss =  parameters$subss

n = subss
mu1 = -8
mu2 = -3
sd1 = 8
sd2 = 10
cor =  parameters$cor



effectsize = c()
correlation = c()
for(i in 1:2000){
  
  dd = faux::rnorm_multi(n, mu = c(mu1,mu2), sd = c(sd1,sd2), r = cor)
  f = ef(dd)
  
  correlation[i] = cor.test(dd$X1, dd$X2)$estimate[[1]]
  effectsize[i] = f
}

effectsize = data.frame(effectsize = effectsize) %>% mutate(cor = parameters$cor, subs = parameters$subss)

return(effectsize)
}

parameters = expand.grid(subss = seq(10,100,length.out = 4),
                        cor = seq(0,0.9,length.out = 4)) %>% mutate(id = 1:n())

data_list <- split(parameters, parameters$id)
  

cores = 8
plan(multisession, workers = cores)

possfit_model = possibly(.f = get_eff, otherwise = "Error")

results <- future_map(data_list, ~possfit_model(.x), .options = furrr_options(seed = TRUE), .progress = T)

df = map_dfr(results,bind_rows)

dq = df %>% mutate(trials = list(c(20,50,100,150))) %>% unnest() %>% group_by(subs,trials,cor) %>% 
  summarize(mean = mean(effectsize), sd = sd(effectsize)) %>% mutate(cor = as.factor(cor))


histogram_observedeffectsize = df %>% mutate(cor = as.factor(cor)) %>% rename(correlation = cor) %>% ggplot(aes(x = effectsize, fill = correlation))+
  facet_wrap(~subs, scales = "free", labeller = label_both, ncol = 4)+geom_histogram(col = "black", alpha = 0.8, position = "identity")+theme_classic()+xlab("Observed effectsize")+theme(legend.position = "top")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 4))+geom_vline(xintercept = 0, linetype = 2)

histogram_observedeffectsize

ggsave(here::here("Figures","histogram_observedeffectsize.PNG"), histogram_observedeffectsize, height = 5,width = 7)


```



# plot 22 probability of rejecting effectsize on probability of effectsize:


# plotting effectsizes:


```{r}
d = as_draws_df(fit_test_logistic_int$summary(c("expo_alpha","expo_beta","intercept_alpha","intercept_beta")))
d = d %>% select(variable, mean) %>% pivot_wider(values_from = "mean",names_from = "variable")

names(d)[1:8] = c("expo_alpha1","expo_alpha2","expo_alpha3",
             "expo_beta1","expo_beta2","expo_beta3",
             "intercept_alpha","intercept_beta")



get_matrix = function(d, subbers, trials){

bigdf = data.frame()

for(subs in subbers){

  for(trial in trials){

    data = d %>% rowwise() %>% 
      mutate(alpha = exp(intercept_alpha) * subs ^ expo_alpha1 * trial^expo_alpha2 * (trial+subs) ^expo_alpha3,
             beta = exp(intercept_beta) * subs ^ expo_beta1 * trial^expo_beta2 * (trial+subs) ^expo_beta3)%>% 
      mutate(power = list(psychometric_logistic(seq(-1,2,by = 0.01), alpha, beta)),
           obs_effectsize = list(seq(-1,2,by = 0.01))) %>% 
    unnest() %>% mutate(subjects = subs, trials = trial)
    
    bigdf = rbind(data,bigdf)

  }
}
return(bigdf)
}

subbers = seq(5,110, by = 5)
trials = c(20,50,100,150)
ddf = get_matrix(d, subbers,trials)

ddf = ddf %>% group_by(obs_effectsize, subjects,trials) %>% summarize(mean_power = round(mean(power),2)) 

ddf

subtract = 0.03

filtered_data <- ddf %>% filter(mean_power < 0.80+subtract & mean_power > 0.80-subtract)


library(ggforce)
ddf %>% ggplot()+geom_raster(aes(x = subjects, y = obs_effectsize, fill = mean_power))+
  scale_fill_continuous(type = "viridis")+facet_wrap(~trials)+
    geom_ellipse(aes(x0 = 30, y0 = 0.4, a = 1, b = 0.2, angle = 0))+
  geom_line(data = filtered_data, aes(x = subjects, y = obs_effectsize), color = "black")


```

# combine it :

```{r, fig.height=7.2, fig.width=7.2}
mu1 = -8
mu2 = -3
sd1 = 8
sd2 = 10
latent_effectsize = (5*sqrt(2*(1-0.5)))/sqrt(sd1^2+sd2^2-2*0.5*sd1*sd2)


power_area_with_ellipses = ddf %>% ggplot()+geom_raster(aes(x = subjects, y = obs_effectsize, fill = mean_power))+
  scale_fill_continuous(type = "viridis")+facet_wrap(~trials, labeller = label_both, ncol = 2)+
#    geom_ellipse(aes(x0 = 30, y0 = 0.4, a = 1, b = 0.5, angle = 0))+
  geom_ellipse(data = dq %>% rename(correlation = cor), aes(x0 = subs, y0 = mean, a = 1.5, b = 2*sd, angle = 0, col = correlation))+
  theme_classic()+geom_hline(yintercept = latent_effectsize, linetype = 2)+
  ylab("Observed effectsize")+
  theme(legend.position = "top")

power_area_with_ellipses

ggsave(here::here("Figures","power_area_with_ellipses.PNG"), power_area_with_ellipses, height = 7.2,width = 7.2)


```



# plot 23 with and without sampling varability  and Gpower


```{r}
psychometric_logistic = function(x, alpha,beta){
  return(1/(1+exp(-(1/beta) * (x - alpha))))
}


psi_function = function(df1){
  
  
  data = df1 %>% 
      mutate(alpha = exp(intercept_alpha) * subs ^ expo_alpha1 * trial^expo_alpha2 * (trial+subs) ^expo_alpha3,
             beta = exp(intercept_beta) * subs ^ expo_beta1 * trial^expo_beta2 * (trial+subs) ^expo_beta3)%>% 
      mutate(power = psychometric_logistic(observed_effectsize, alpha, beta)) %>%  
    mutate(subjects = subs, trials = trial)
    
}



n = 40
sd1 = 8
sd2 = 8

#meandif = effect_size * (blablalab) / blablalba
meandif = (seq(0,0.5,by = 0.1) * sqrt(sd1^2+sd2^2-2*0.5*sd1*sd2)) / sqrt(2*(1-0.5))

# we use mean effect size = 0.5 so mean dif = 4
mu1 = -8
mu2 = (-8 + meandif[6])

effectsize = c()
correlation = c()
for(i in 1:4000){

  cor =  rnorm(1,0.54, 0.02)
  
  dd = faux::rnorm_multi(n, mu = c(mu1,mu2), sd = c(sd1,sd2), r = cor)
  f = ef(dd)
  
  correlation[i] = cor.test(dd$X1, dd$X2)$estimate[[1]]
  effectsize[i] = f
}

hist(effectsize)
```


```{r}

ef = function(dd){
  return((mean(dd$X2-dd$X1) * sqrt(2*(1-cor.test(dd$X1, dd$X2)$estimate[[1]]))) / sqrt(sd(dd$X1)^2 + sd(dd$X2)^2 - 2 * sd(dd$X1) * sd(dd$X2) * cor.test(dd$X1, dd$X2)$estimate[[1]]))    
}


get_power_per_trials = function(d_logistic_int, params){

  
  n = params$subs
  sd1 = 8
  sd2 = 8
  
  #meandif = effect_size * (blablalab) / blablalba
  #meandif = (seq(0,0.5,by = 0.1) * sqrt(sd1^2+sd2^2-2*sd1*sd2*0.54)) / sqrt(2*(1-0.54))
  
  # we use mean effect size = 0.5 so mean dif = 4
  mu1 = -8
  mu2 = (-8 + 4)
  
  effectsize = c()
  correlation = c()
  for(i in 1:4000){

    cor =  rnorm(1,0.54, 0.05)

    dd = faux::rnorm_multi(n, mu = c(mu1,mu2), sd = c(sd1,sd2), r = cor)

    f = ef(dd)

    effectsize[i] = f
  }
  
  d_logistic_int$observed_effectsize = effectsize
  d_logistic_int$trial = params$trials
  d_logistic_int$subs = params$subs
  
  
  
  qr = d_logistic_int %>% 
        mutate(alpha = exp(intercept_alpha) * subs ^ expo_alpha1 * trial^expo_alpha2 * (trial+subs) ^expo_alpha3,
               beta = exp(intercept_beta) * subs ^ expo_beta1 * trial^expo_beta2 * (trial+subs) ^expo_beta3) %>% 
    rowwise() %>% 
        mutate(power = psychometric_logistic(observed_effectsize, alpha, beta)) %>%  
      mutate(subjects = subs, trials = trial)
    
  data.frame(power = sum(qr$power > 0.8)/4000, trials = params$trials,subs = params$subs, replication = params$replicate)
}


trials = seq(10,200,by = 10)
subs = seq(50,150,by = 5)

replicate = 1:3


parameters = expand.grid(trials = trials,
                        replicate = replicate,
                        subs = subs) %>% mutate(id = 1:n())

data_list <- split(parameters, parameters$id)
  
cores = 20
plan(multisession, workers = cores)

possfit_model = possibly(.f = get_power_per_trials, otherwise = "Error")

results <- future_map(data_list, ~possfit_model(d_logistic_int,.x), .options = furrr_options(seed = TRUE), .progress = T)

df_un = map_dfr(results,bind_rows)


df_un %>% group_by(trials, subs) %>% summarize(mean = mean(power), sd = sd(power)) %>% 
  ggplot()+
  geom_pointrange(aes(x = trials, y = mean, ymin = mean-2*sd, ymax = mean+2*sd, col = subs))+facet_wrap(~subs)


subtract = 0.01

linedata = df_un %>% group_by(trials, subs) %>% summarize(mean_power = round(mean(power),3)) %>% 
  filter(mean_power < 0.8+subtract & mean_power > 0.8-subtract)

pun = df_un %>% 
  group_by(trials, subs) %>% summarize(mean_power = round(mean(power),3))%>% 
  ungroup() %>% 
  add_row(mean_power = c(1,0), trials = c(NA,NA), subs = c(NA,NA)) %>% 
  ggplot()+
  geom_raster(aes(x = trials, y = subs, fill = mean_power))+
  geom_line(data = linedata, aes(x = trials, y = subs), col = "black")+
  scale_fill_continuous(type = "viridis", breaks = c(0,0.2,0.4,0.6,0.8,1))+theme_classic()+
  scale_y_continuous("Subjects", breaks = seq(50,150,by = 10), limits = c(50,150))+
  scale_x_continuous("Trials", breaks = seq(10,205,by = 30), limits = c(10,205))



pun
```


#without uncertainty
```{r, fig.height=7.2, fig.width=7.2}

get_power_per_trials_no_unc = function(d_logistic_int, params){

  
  n = params$subs
  sd1 = 8
  sd2 = 8
  
  #meandif = effect_size * (blablalab) / blablalba
  meandif = (seq(0,0.5,by = 0.1) * sqrt(sd1^2+sd2^2-2*0.54*sd1*sd2)) / sqrt(2*(1-0.54))
  
  # we use mean effect size = 0.5 so mean dif = 4
  mu1 = -8
  mu2 = (-8 + 2)
  
  effectsize = 0.5

  d_logistic_int$observed_effectsize = effectsize
  d_logistic_int$trial = params$trials
  d_logistic_int$subs = params$subs
  
  
  
  qr = d_logistic_int %>% 
        mutate(alpha = exp(intercept_alpha) * subs ^ expo_alpha1 * trial^expo_alpha2 * (trial+subs) ^expo_alpha3,
               beta = exp(intercept_beta) * subs ^ expo_beta1 * trial^expo_beta2 * (trial+subs) ^expo_beta3) %>% 
    rowwise() %>% 
        mutate(power = psychometric_logistic(observed_effectsize, alpha, beta)) %>%  
      mutate(subjects = subs, trials = trial)
    
  data.frame(power = sum(qr$power > 0.8)/4000, trials = params$trials,subs = params$subs, replication = params$replicate)
}


trials = seq(10,200,by = 2)
subs = seq(10,70,by = 1)

replicate = 1


parameters = expand.grid(trials = trials,
                        replicate = replicate,
                        subs = subs) %>% mutate(id = 1:n())

data_list <- split(parameters, parameters$id)
  

cores = 20
plan(multisession, workers = cores)

possfit_model = possibly(.f = get_power_per_trials_no_unc, otherwise = "Error")

results <- future_map(data_list, ~possfit_model(d_logistic_int,.x), .options = furrr_options(seed = TRUE), .progress = T)

df_noun = map_dfr(results,bind_rows)


# 
# df_noun %>% group_by(trials, subs) %>% summarize(mean = mean(power), sd = sd(power)) %>% 
#   ggplot(aes(x = trials, y = mean, ymin = mean-2*sd, ymax = mean+2*sd, col = subs))+
#   geom_pointrange(position=position_dodge(width = 0.2))+facet_wrap(~subs)




subtract = 0.05
linedata2 = df_noun %>% group_by(trials, subs) %>% summarize(mean_power = round(mean(power),3)) %>% filter(mean_power < 0.8+subtract & mean_power > 0.8-subtract)

p_noun = df_noun %>% group_by(trials, subs) %>% summarize(mean_power = round(mean(power),3)) %>% 
  ggplot()+geom_raster(aes(x = trials, y = subs, fill = mean_power))+
  geom_line(data = linedata2, aes(x = trials, y = subs), col = "black", alpha = 0.7)+
#  geom_line(data = linedata, aes(x = trials, y = subs), col = "red")+
  scale_fill_continuous(type = "viridis", breaks = c(0,0.2,0.4,0.6,0.8,1))+theme_classic()+
  scale_y_continuous("Subjects", breaks = seq(30,70,by = 10), limits = c(30,70))+
  scale_x_continuous("Trials", breaks = seq(10,200,by = 30), limits = c(10,200))+
  guides(fill=guide_legend(title="Mean power"))+
  theme(text=element_text(size=16), #change font size of all text
        axis.text=element_text(size=16), #change font size of axis text
        axis.title=element_text(size=16), #change font size of axis titles
        plot.title=element_text(size=16), #change font size of plot title
        legend.text=element_text(size=16), #change font size of legend text
        legend.title=element_text(size=16)) #change font size of legend title   

p_noun

```
# replicate gpower

```{r}

get_power_gpower = function(params){

  
  n = params$subs
  sd1 = 8
  sd2 = 8
  
  # we use mean effect size = 0.5 so mean dif = 4
  mu1 = -8
  mu2 = (-8 + 4)
  
  
  effectsize = c()
  correlation = c()
  pval = c()
  for(i in 1:4000){

    cor =  rnorm(1,0.54, 0.05)

    dd = faux::rnorm_multi(n, mu = c(mu1,mu2), sd = c(sd1,sd2), r = cor)

    f = ef(dd)

    q = t.test(dd$X1,dd$X2,alternative = "less", paired = T)

    pval[i] = q$p.value
    
    effectsize[i] = f
  }
  
  data.frame(power = sum(pval < 0.05)/4000, subs = params$subs, replication = params$replicate)
}


subs = seq(10,40,by = 1)

replicate = 1


parameters = expand.grid(replicate = replicate,
                        subs = subs) %>% mutate(id = 1:n())

data_list <- split(parameters, parameters$id)
  

# cores = 8
# plan(multisession, workers = cores)

possfit_model = possibly(.f = get_power_gpower, otherwise = "Error")

results <- future_map(data_list, ~possfit_model(.x), .options = furrr_options(seed = TRUE), .progress = T)

df_noun = map_dfr(results,bind_rows)


df_noun
```



```{r, fig.width=7.2,fig.height=7.2}
library(patchwork)

power_sampling_varability_and_gpower = p_noun+geom_segment(aes(y = 25, yend = 25, x = 10, xend = 200),linetype = 2, col = "red")+
  pun+geom_segment(aes(y = 25, yend = 25, x = 10, xend = 200),linetype = 2, col = "red")+ 
  plot_layout(guides = "collect")&theme(legend.position = "top")

power_sampling_varability_and_gpower

ggsave(here::here("Figures","power_sampling_varability_and_gpower.PNG"), power_sampling_varability_and_gpower, height = 7.2,width = 7.2)


```
